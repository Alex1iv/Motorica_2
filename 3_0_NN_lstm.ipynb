{"cells":[{"cell_type":"markdown","id":"rPi8auIvSEP1","metadata":{"id":"rPi8auIvSEP1"},"source":["# LSTMx4 st12_9_temp +3 LB = 0.95"]},{"cell_type":"markdown","id":"vjg3Qaa6DDfu","metadata":{"id":"vjg3Qaa6DDfu"},"source":["### Import libs"]},{"cell_type":"code","execution_count":1,"id":"KwbDwvigm8lh","metadata":{"id":"KwbDwvigm8lh"},"outputs":[],"source":["# Путь расположения файлов, если меняется, то заменить\n","# Папка с исходными файлами 'X_test.npy', 'X_train.npy', 'y_train.csv', 'sample_submission.csv'\n","#PATH = '/content/drive/MyDrive/Motorica/'"]},{"cell_type":"code","execution_count":1,"id":"ZJ6MNepRSEP3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23842,"status":"ok","timestamp":1664209317387,"user":{"displayName":"Oleg Strebkov","userId":"12295069352902457105"},"user_tz":-180},"id":"ZJ6MNepRSEP3","outputId":"3cfc60e5-b73a-4542-bff9-b487a5c8a997"},"outputs":[],"source":["# Поключение google drive для для чтения файлов\n","#from google.colab import drive\n","#drive.mount('/content/drive', force_remount=True)\n","import os\n","PATH = \"\"\n","\n","#print(os.listdir(PATH))\n","\n","# Папка для сохранения моделей и файлов\n","PATH_BEST_MODEL = os.path.join(PATH, 'best_models/')\n","\n","# Импорты необходимых библиотек\n","import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import tensorflow as tf\n","from keras import backend as K\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"]},{"cell_type":"code","execution_count":12,"id":"b55282c7","metadata":{},"outputs":[],"source":["# библиотека вызова функций\n","import Motorica_2 as m"]},{"cell_type":"markdown","id":"4e2fd9b3","metadata":{},"source":["## Преобразование данных с помощью скользящего среднеквадратического отклонения\n","\n","Для преобразования y_train на основании сигналов датчиков с"]},{"cell_type":"code","execution_count":16,"id":"7xZMH8hg5j1H","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xZMH8hg5j1H","outputId":"80bbae09-40dd-408d-81e7-d78e85ca0000"},"outputs":[{"name":"stdout","output_type":"stream","text":["(323, 100)\n"]}],"source":["import __init__\n","X_train = __init__.X_train\n","y_train = __init__.y_train\n","\n","y_train_ch = []\n","for id in range(X_train.shape[0]):\n","    \n","    df0_T = pd.DataFrame(data=X_train[id], \n","                         index=range(X_train.shape[1]), \n","                         columns=range(X_train.shape[2])).T\n","    y_k = y_train[id*100:(id+1)*100].reset_index().T.loc['class'].values\n","    \n","    # будем изменять только те наблюдения y_train, в которых происходит изменение жеста\n","    if np.sum(y_k)!=0: \n","    # строим скользящее STD\n","        time_stp = 0\n","        time_end = 100\n","        df_T_stp = df0_T.iloc[time_stp:time_end]\n","        df_T_stp_std_1 = df_T_stp.rolling(window=5).std().dropna(axis=0)\n","        \n","        # выбираем активные датчики\n","        strong_sens_list = m.get_sensor_list(id) \n","\n","        # рассчитываем начало времени выполнения жеста, исходя из медианного значения скользящего std, \n","        # для которого превышен порог 15 по каждому активному датчику, \n","        # с последующим выбором медианы из полученного списка \n","        grow_ind = int(\n","            np.median([np.median(np.nonzero((df_T_stp_std_1[x]>15).values)[0]) \\\n","                       for x in strong_sens_list \\\n","                       if np.any(np.nonzero((df_T_stp_std_1[x]>15).values)[0])])) + 3\n","\n","        # преобразование строки y_train:\n","        y_k_ch = np.empty(100)\n","        y_k_ch[:grow_ind].fill(y_k[0]) # до grow_ind - заполняем первым значением k-го наблюдения из y_train\n","        y_k_ch[grow_ind:].fill(y_k[-1]) # после grow_ind - последним значением k-го наблюдения из y_train\n","        y_train_ch.append(y_k_ch)\n","    \n","    else:\n","        y_k_ch = np.zeros(100)\n","        y_train_ch.append(y_k_ch)\n","\n","y_train_ch = np.array(y_train_ch)\n","print(y_train_ch.shape)"]},{"cell_type":"markdown","id":"PNKypdTYz_1I","metadata":{"id":"PNKypdTYz_1I"},"source":["Посмотрим, что получилось после преобразования:"]},{"cell_type":"code","execution_count":24,"id":"JGavJRgA-zS7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":473},"id":"JGavJRgA-zS7","outputId":"ce7d6e47-8fe3-4ce7-efc5-0e9f905d1906"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 720x432 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Наблюдение 7\n","id=7 \n","\n","plot_counter = 1\n","\n","df0_T = pd.DataFrame(data=X_train[id], \n","                         index=range(X_train.shape[1]), \n","                         columns=range(X_train.shape[2])).T\n","df_T_stp = df0_T\n","df_T_stp_std_1 = df_T_stp.rolling(window=5).std().dropna(axis=0)\n","\n","\n","fig, ax = plt.subplots(2, 1, figsize=(10,6)) #sharex=True\n","\n","plt.subplots_adjust(  left=0.1,   right=0.9,\n","                    bottom=0.1,     top=0.9,\n","                    wspace=0.1,  hspace=0.3)\n","\n","plt.suptitle(f'Рис. {plot_counter}'+' - преобразование сигналов y_train \\n скользящим среднеквадратическим отклонением', y=-0.01, fontsize=16)\n","\n","ax[0].plot(pd.DataFrame(df_T_stp_std_1))\n","ax[0].set_ylabel('Сигнал датчика')\n","ax[0].set_xlabel('Время')\n","\n","ax[1].plot(y_train_ch[id])\n","ax[1].set_yticks(\n","                  np.arange(9),\n","                  ['Open', 'Pinky', 'Ring', 'Middle', 'Pistol', 'Index', 'Thumb', 'OK', 'Grab']\n",")\n","ax[1].set_xlabel('Время')\n","    \n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"vC6k7Onw3m45","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vC6k7Onw3m45","outputId":"7a0e8de5-f06f-4e18-aff9-dc68fc3fd348"},"outputs":[],"source":["# # Можно пробежаться по всем 323 наблюдениям X_train и измененного y_train для визуального анализа преобразований\n","# for i in range(X_train.shape[0]):\n","#     fig, axx = plt.subplots(2, 1, figsize=(10,6), sharex=True)\n","#     axx[0].plot(pd.DataFrame(X_train[i].T))\n","#     axx[0].legend()\n","#     axx[1].plot(y_train_ch[i])\n","#     axx[1].set_yticks(\n","#         np.arange(9),\n","#         ['Open', 'Pinky', 'Ring', 'Middle', 'Pistol', 'Index', 'Thumb', 'OK', 'Grab']\n","#     )\n","#     plt.suptitle(f'Train {i}')\n","#     plt.show()"]},{"cell_type":"markdown","id":"_Vr_Ate3kHgd","metadata":{"id":"_Vr_Ate3kHgd"},"source":["Данные для подачи в модель подготовлены, перейдем к построению модели.   \n","Для начала рассмотрим Baseline, предложенный организаторами соревнования.\n"]},{"cell_type":"markdown","id":"729317ea-f0ef-478e-a854-0901a35dc330","metadata":{"id":"729317ea-f0ef-478e-a854-0901a35dc330"},"source":["## NN Baseline"]},{"cell_type":"markdown","id":"385327d2-f8ae-48c9-b435-d7da8b4451f9","metadata":{"id":"385327d2-f8ae-48c9-b435-d7da8b4451f9"},"source":["### Model architecture baseline"]},{"cell_type":"code","execution_count":33,"id":"MC1aNcUC1alS","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MC1aNcUC1alS","outputId":"3c99a25e-3e96-4b62-aeb9-a102d48b191f"},"outputs":[{"name":"stdout","output_type":"stream","text":["(323, 100, 40) (323, 100, 9)\n","(54, 100, 40)\n"]}],"source":["import __init__\n","X_train = __init__.X_train\n","X_test = __init__.X_test\n","y_train = __init__.y_train\n","\n","#y_train[['sample_id', 'timestep']] = y_train['sample-timestep'].str.split('-', 1, expand=True).astype(int)\n","y_train = y_train.pivot(index='sample', columns='timestep', values='class')\n","y_train_index = y_train.index\n","y_train = y_train.sort_index() # на всякий случай\n","y_train = y_train.values\n","\n","X_train_nn = X_train.swapaxes(1, 2)\n","X_test_nn = X_test.swapaxes(1, 2)\n","y_train_nn = tf.keras.utils.to_categorical(y_train)\n","\n","print(X_train_nn.shape, y_train_nn.shape)\n","print(X_test_nn.shape)"]},{"cell_type":"code","execution_count":34,"id":"67417a64-69e1-4581-8db0-6c09091be12a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67417a64-69e1-4581-8db0-6c09091be12a","outputId":"0bd66f91-b2e0-45a3-efa6-6c7de6936f34"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"Model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 100, 40)]         0         \n","                                                                 \n"," simple_rnn (SimpleRNN)      (None, 100, 100)          14100     \n","                                                                 \n"," simple_rnn_1 (SimpleRNN)    (None, 100, 100)          20100     \n","                                                                 \n"," dense (Dense)               (None, 100, 9)            909       \n","                                                                 \n","=================================================================\n","Total params: 35,109\n","Trainable params: 35,109\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["tf.keras.backend.clear_session()\n","\n","input_channels = x = tf.keras.layers.Input(\n","    (X_train.shape[2], X_train.shape[1]),\n",")\n","x = tf.keras.layers.SimpleRNN(\n","    units=X_train.shape[2],\n","    return_sequences=True,\n","    recurrent_regularizer=tf.keras.regularizers.L1L2(l1=1e-2, l2=1e-3),\n","    dropout=0.0,\n","    recurrent_dropout=0.0,\n",")(x)\n","x = tf.keras.layers.SimpleRNN(\n","    units=X_train.shape[2],\n","    return_sequences=True,\n","    recurrent_regularizer=tf.keras.regularizers.L1L2(l1=1e-2, l2=1e-3),\n","    dropout=0.0,\n","    recurrent_dropout=0.0,\n",")(x)\n","output = tf.keras.layers.Dense(units=9, activation='sigmoid')(x) \n","\n","model_baseline = tf.keras.Model(\n","    inputs=input_channels,\n","    outputs=output,\n","    name=\"Model\"\n",")\n","\n","model_baseline.compile(\n","    loss=\"categorical_crossentropy\",\n","    metrics=[\n","        \"accuracy\",\n","    ],\n","    optimizer=tf.keras.optimizers.Adam(), # learning_rate=1e-2\n",")\n","model_baseline.summary()"]},{"cell_type":"code","execution_count":35,"id":"48395d99-1222-43b8-9a3a-a15651a718bf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48395d99-1222-43b8-9a3a-a15651a718bf","outputId":"6d44f0e2-b162-487f-98f7-ba52b17f754b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n","11/11 [==============================] - 2s 26ms/step - loss: 17.3307 - accuracy: 0.4619\n","Epoch 2/200\n","11/11 [==============================] - 0s 26ms/step - loss: 15.2233 - accuracy: 0.5557\n","Epoch 3/200\n","11/11 [==============================] - 0s 25ms/step - loss: 13.4805 - accuracy: 0.5751\n","Epoch 4/200\n","11/11 [==============================] - 0s 25ms/step - loss: 11.9152 - accuracy: 0.6140\n","Epoch 5/200\n","11/11 [==============================] - 0s 25ms/step - loss: 10.4968 - accuracy: 0.6073\n","Epoch 6/200\n","11/11 [==============================] - 0s 26ms/step - loss: 9.1966 - accuracy: 0.6552\n","Epoch 7/200\n","11/11 [==============================] - 0s 25ms/step - loss: 8.0578 - accuracy: 0.6894\n","Epoch 8/200\n","11/11 [==============================] - 0s 25ms/step - loss: 7.0739 - accuracy: 0.6715\n","Epoch 9/200\n","11/11 [==============================] - 0s 25ms/step - loss: 6.1753 - accuracy: 0.6988\n","Epoch 10/200\n","11/11 [==============================] - 0s 25ms/step - loss: 5.3819 - accuracy: 0.7138\n","Epoch 11/200\n","11/11 [==============================] - 0s 25ms/step - loss: 4.6797 - accuracy: 0.7073\n","Epoch 12/200\n","11/11 [==============================] - 0s 26ms/step - loss: 4.0566 - accuracy: 0.7288\n","Epoch 13/200\n","11/11 [==============================] - 0s 26ms/step - loss: 3.5306 - accuracy: 0.7324\n","Epoch 14/200\n","11/11 [==============================] - 0s 25ms/step - loss: 3.0864 - accuracy: 0.7368\n","Epoch 15/200\n","11/11 [==============================] - 0s 25ms/step - loss: 2.7255 - accuracy: 0.7406\n","Epoch 16/200\n","11/11 [==============================] - 0s 25ms/step - loss: 2.4001 - accuracy: 0.7507\n","Epoch 17/200\n","11/11 [==============================] - 0s 26ms/step - loss: 2.1753 - accuracy: 0.7176\n","Epoch 18/200\n","11/11 [==============================] - 0s 25ms/step - loss: 1.9440 - accuracy: 0.7343\n","Epoch 19/200\n","11/11 [==============================] - 0s 26ms/step - loss: 1.7686 - accuracy: 0.7364\n","Epoch 20/200\n","11/11 [==============================] - 0s 27ms/step - loss: 1.5947 - accuracy: 0.7364\n","Epoch 21/200\n","11/11 [==============================] - 0s 25ms/step - loss: 1.4430 - accuracy: 0.7505\n","Epoch 22/200\n","11/11 [==============================] - 0s 26ms/step - loss: 1.3254 - accuracy: 0.7554\n","Epoch 23/200\n","11/11 [==============================] - 0s 26ms/step - loss: 1.2416 - accuracy: 0.7663\n","Epoch 24/200\n","11/11 [==============================] - 0s 25ms/step - loss: 1.1628 - accuracy: 0.7723\n","Epoch 25/200\n","11/11 [==============================] - 0s 26ms/step - loss: 1.1014 - accuracy: 0.7632\n","Epoch 26/200\n","11/11 [==============================] - 0s 27ms/step - loss: 1.0280 - accuracy: 0.7807\n","Epoch 27/200\n","11/11 [==============================] - 0s 25ms/step - loss: 1.0405 - accuracy: 0.7543\n","Epoch 28/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.9719 - accuracy: 0.7665\n","Epoch 29/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.9610 - accuracy: 0.7566\n","Epoch 30/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.9353 - accuracy: 0.7675\n","Epoch 31/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.9322 - accuracy: 0.7480\n","Epoch 32/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.9212 - accuracy: 0.7436\n","Epoch 33/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8958 - accuracy: 0.7675\n","Epoch 34/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.9454 - accuracy: 0.7370\n","Epoch 35/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8923 - accuracy: 0.7534\n","Epoch 36/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8881 - accuracy: 0.7541\n","Epoch 37/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8518 - accuracy: 0.7802\n","Epoch 38/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8404 - accuracy: 0.7651\n","Epoch 39/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8327 - accuracy: 0.7693\n","Epoch 40/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8358 - accuracy: 0.7826\n","Epoch 41/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8341 - accuracy: 0.7649\n","Epoch 42/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8275 - accuracy: 0.7635\n","Epoch 43/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8471 - accuracy: 0.7561\n","Epoch 44/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8366 - accuracy: 0.7711\n","Epoch 45/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8459 - accuracy: 0.7542\n","Epoch 46/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8311 - accuracy: 0.7688\n","Epoch 47/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8389 - accuracy: 0.7681\n","Epoch 48/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8244 - accuracy: 0.7844\n","Epoch 49/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8232 - accuracy: 0.7869\n","Epoch 50/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8105 - accuracy: 0.7798\n","Epoch 51/200\n","11/11 [==============================] - 0s 28ms/step - loss: 0.8090 - accuracy: 0.7763\n","Epoch 52/200\n","11/11 [==============================] - 0s 27ms/step - loss: 0.8206 - accuracy: 0.7734\n","Epoch 53/200\n","11/11 [==============================] - 0s 29ms/step - loss: 0.8179 - accuracy: 0.7697\n","Epoch 54/200\n","11/11 [==============================] - 0s 28ms/step - loss: 0.8091 - accuracy: 0.7907\n","Epoch 55/200\n","11/11 [==============================] - 0s 28ms/step - loss: 0.7981 - accuracy: 0.7744\n","Epoch 56/200\n","11/11 [==============================] - 0s 27ms/step - loss: 0.7967 - accuracy: 0.7822\n","Epoch 57/200\n","11/11 [==============================] - 0s 27ms/step - loss: 0.8023 - accuracy: 0.7772\n","Epoch 58/200\n","11/11 [==============================] - 0s 27ms/step - loss: 0.7824 - accuracy: 0.7892\n","Epoch 59/200\n","11/11 [==============================] - 0s 29ms/step - loss: 0.7884 - accuracy: 0.7836\n","Epoch 60/200\n","11/11 [==============================] - 0s 28ms/step - loss: 0.8249 - accuracy: 0.7643\n","Epoch 61/200\n","11/11 [==============================] - 0s 29ms/step - loss: 0.8264 - accuracy: 0.7774\n","Epoch 62/200\n","11/11 [==============================] - 0s 27ms/step - loss: 0.8497 - accuracy: 0.7621\n","Epoch 63/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8173 - accuracy: 0.7746\n","Epoch 64/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8029 - accuracy: 0.7814\n","Epoch 65/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8165 - accuracy: 0.7754\n","Epoch 66/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8082 - accuracy: 0.7705\n","Epoch 67/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8115 - accuracy: 0.7700\n","Epoch 68/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7927 - accuracy: 0.7827\n","Epoch 69/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7900 - accuracy: 0.7794\n","Epoch 70/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8178 - accuracy: 0.7708\n","Epoch 71/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7950 - accuracy: 0.7767\n","Epoch 72/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8160 - accuracy: 0.7821\n","Epoch 73/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8102 - accuracy: 0.7669\n","Epoch 74/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7879 - accuracy: 0.7853\n","Epoch 75/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7985 - accuracy: 0.7710\n","Epoch 76/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7979 - accuracy: 0.7698\n","Epoch 77/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8359 - accuracy: 0.7696\n","Epoch 78/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8184 - accuracy: 0.7712\n","Epoch 79/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8184 - accuracy: 0.7822\n","Epoch 80/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8270 - accuracy: 0.7694\n","Epoch 81/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8743 - accuracy: 0.7305\n","Epoch 82/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8460 - accuracy: 0.7547\n","Epoch 83/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8284 - accuracy: 0.7620\n","Epoch 84/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8114 - accuracy: 0.7582\n","Epoch 85/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8300 - accuracy: 0.7727\n","Epoch 86/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8464 - accuracy: 0.7630\n","Epoch 87/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8428 - accuracy: 0.7584\n","Epoch 88/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8531 - accuracy: 0.7438\n","Epoch 89/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8711 - accuracy: 0.7470\n","Epoch 90/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8167 - accuracy: 0.7693\n","Epoch 91/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8136 - accuracy: 0.7847\n","Epoch 92/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7852 - accuracy: 0.7867\n","Epoch 93/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8147 - accuracy: 0.7661\n","Epoch 94/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8101 - accuracy: 0.7657\n","Epoch 95/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8093 - accuracy: 0.7738\n","Epoch 96/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8467 - accuracy: 0.7745\n","Epoch 97/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8297 - accuracy: 0.7600\n","Epoch 98/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7982 - accuracy: 0.7791\n","Epoch 99/200\n","11/11 [==============================] - 0s 28ms/step - loss: 0.8310 - accuracy: 0.7649\n","Epoch 100/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7773 - accuracy: 0.7804\n","Epoch 101/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7558 - accuracy: 0.7937\n","Epoch 102/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7544 - accuracy: 0.7950\n","Epoch 103/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7865 - accuracy: 0.7842\n","Epoch 104/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8165 - accuracy: 0.7723\n","Epoch 105/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7717 - accuracy: 0.7983\n","Epoch 106/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7548 - accuracy: 0.7915\n","Epoch 107/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7698 - accuracy: 0.7861\n","Epoch 108/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7466 - accuracy: 0.8010\n","Epoch 109/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7554 - accuracy: 0.7975\n","Epoch 110/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7950 - accuracy: 0.7634\n","Epoch 111/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8334 - accuracy: 0.7478\n","Epoch 112/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8082 - accuracy: 0.7529\n","Epoch 113/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7911 - accuracy: 0.7695\n","Epoch 114/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7966 - accuracy: 0.7711\n","Epoch 115/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8118 - accuracy: 0.7643\n","Epoch 116/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8134 - accuracy: 0.7598\n","Epoch 117/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8224 - accuracy: 0.7621\n","Epoch 118/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.9144 - accuracy: 0.7279\n","Epoch 119/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8889 - accuracy: 0.7341\n","Epoch 120/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8452 - accuracy: 0.7500\n","Epoch 121/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8240 - accuracy: 0.7655\n","Epoch 122/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8629 - accuracy: 0.7549\n","Epoch 123/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.9031 - accuracy: 0.7232\n","Epoch 124/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8973 - accuracy: 0.7484\n","Epoch 125/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.9026 - accuracy: 0.7367\n","Epoch 126/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.9143 - accuracy: 0.7344\n","Epoch 127/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.9299 - accuracy: 0.7198\n","Epoch 128/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.9008 - accuracy: 0.7341\n","Epoch 129/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8779 - accuracy: 0.7455\n","Epoch 130/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8702 - accuracy: 0.7506\n","Epoch 131/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8708 - accuracy: 0.7393\n","Epoch 132/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8935 - accuracy: 0.7330\n","Epoch 133/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8928 - accuracy: 0.7339\n","Epoch 134/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8744 - accuracy: 0.7542\n","Epoch 135/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8498 - accuracy: 0.7506\n","Epoch 136/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8327 - accuracy: 0.7526\n","Epoch 137/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8496 - accuracy: 0.7596\n","Epoch 138/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8415 - accuracy: 0.7637\n","Epoch 139/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8463 - accuracy: 0.7526\n","Epoch 140/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8243 - accuracy: 0.7618\n","Epoch 141/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8668 - accuracy: 0.7566\n","Epoch 142/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8637 - accuracy: 0.7622\n","Epoch 143/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8726 - accuracy: 0.7522\n","Epoch 144/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.9166 - accuracy: 0.7301\n","Epoch 145/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.9522 - accuracy: 0.7074\n","Epoch 146/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.9190 - accuracy: 0.7315\n","Epoch 147/200\n","11/11 [==============================] - 0s 28ms/step - loss: 0.9293 - accuracy: 0.7359\n","Epoch 148/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8921 - accuracy: 0.7510\n","Epoch 149/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8743 - accuracy: 0.7396\n","Epoch 150/200\n","11/11 [==============================] - 0s 28ms/step - loss: 0.8740 - accuracy: 0.7492\n","Epoch 151/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8866 - accuracy: 0.7249\n","Epoch 152/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8820 - accuracy: 0.7337\n","Epoch 153/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8723 - accuracy: 0.7497\n","Epoch 154/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8670 - accuracy: 0.7453\n","Epoch 155/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8663 - accuracy: 0.7428\n","Epoch 156/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8430 - accuracy: 0.7533\n","Epoch 157/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8734 - accuracy: 0.7483\n","Epoch 158/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8554 - accuracy: 0.7668\n","Epoch 159/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8257 - accuracy: 0.7636\n","Epoch 160/200\n","11/11 [==============================] - 0s 28ms/step - loss: 0.8523 - accuracy: 0.7583\n","Epoch 161/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8251 - accuracy: 0.7652\n","Epoch 162/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8028 - accuracy: 0.7655\n","Epoch 163/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8480 - accuracy: 0.7554\n","Epoch 164/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8231 - accuracy: 0.7676\n","Epoch 165/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8243 - accuracy: 0.7638\n","Epoch 166/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8301 - accuracy: 0.7588\n","Epoch 167/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8575 - accuracy: 0.7573\n","Epoch 168/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8895 - accuracy: 0.7428\n","Epoch 169/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8632 - accuracy: 0.7547\n","Epoch 170/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8241 - accuracy: 0.7565\n","Epoch 171/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8345 - accuracy: 0.7594\n","Epoch 172/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8460 - accuracy: 0.7607\n","Epoch 173/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8357 - accuracy: 0.7641\n","Epoch 174/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8398 - accuracy: 0.7606\n","Epoch 175/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8760 - accuracy: 0.7414\n","Epoch 176/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8676 - accuracy: 0.7494\n","Epoch 177/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8910 - accuracy: 0.7367\n","Epoch 178/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8948 - accuracy: 0.7303\n","Epoch 179/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8861 - accuracy: 0.7446\n","Epoch 180/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.9620 - accuracy: 0.7200\n","Epoch 181/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8880 - accuracy: 0.7345\n","Epoch 182/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8783 - accuracy: 0.7454\n","Epoch 183/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8818 - accuracy: 0.7348\n","Epoch 184/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8743 - accuracy: 0.7470\n","Epoch 185/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8445 - accuracy: 0.7622\n","Epoch 186/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8465 - accuracy: 0.7580\n","Epoch 187/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8948 - accuracy: 0.7371\n","Epoch 188/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8460 - accuracy: 0.7560\n","Epoch 189/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8690 - accuracy: 0.7594\n","Epoch 190/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.8298 - accuracy: 0.7727\n","Epoch 191/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7971 - accuracy: 0.7836\n","Epoch 192/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7688 - accuracy: 0.7969\n","Epoch 193/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7821 - accuracy: 0.7930\n","Epoch 194/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7761 - accuracy: 0.7804\n","Epoch 195/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7948 - accuracy: 0.7729\n","Epoch 196/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7828 - accuracy: 0.7847\n","Epoch 197/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7636 - accuracy: 0.8054\n","Epoch 198/200\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7616 - accuracy: 0.8006\n","Epoch 199/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7508 - accuracy: 0.7954\n","Epoch 200/200\n","11/11 [==============================] - 0s 25ms/step - loss: 0.7746 - accuracy: 0.7888\n"]}],"source":["history = model_baseline.fit(\n","    X_train_nn,\n","    y_train_nn, \n","    epochs=200,\n","    verbose=1\n",")"]},{"cell_type":"markdown","id":"28ab5c4f-9f39-444a-a172-fa70a572d318","metadata":{"id":"28ab5c4f-9f39-444a-a172-fa70a572d318"},"source":["### Visualisation"]},{"cell_type":"code","execution_count":36,"id":"rdy7-njgCxGh","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdy7-njgCxGh","outputId":"0248be47-a2d3-419c-ace9-ddc861103f17"},"outputs":[{"name":"stdout","output_type":"stream","text":["11/11 [==============================] - 0s 10ms/step\n"]},{"data":{"text/plain":["(323, 100, 9)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["y_pred_train_nn = model_baseline.predict(X_train_nn)\n","y_pred_train_nn.shape"]},{"cell_type":"code","execution_count":53,"id":"dee383c2-a330-481e-80d3-ef79b8ee55dc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"dee383c2-a330-481e-80d3-ef79b8ee55dc","outputId":"11002960-de17-4056-e07d-ee793e210613"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 720x576 with 4 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plot_counter = 2 # номер рисунка\n","\n","id = 24\n","\n","fig, ax = plt.subplots(4, 1, sharex=True, figsize=(10, 8))\n","\n","plt.subplots_adjust(  left=0.1,   right=0.9,\n","                    bottom=0.1,     top=0.9,\n","                    wspace=0.1,  hspace=0.3)\n","\n","ax[0].plot(X_train[id].T)\n","ax[0].set_title('Сигналы датчиков ОМГ')\n","\n","ax[1].imshow(y_train_nn[id].T, origin=\"lower\")\n","ax[1].set_aspect('auto')\n","ax[1].set_title('Класс / жест')\n","ax[1].set_yticks(\n","    np.arange(9),\n","    ['Open', 'Pinky', 'Ring', 'Middle', 'Pistol', 'Index', 'Thumb', 'OK', 'Grab']\n",")\n","\n","ax[2].imshow(y_pred_train_nn[id].T, origin=\"lower\") # , vmin=-0.5, vmax=0.5\n","ax[2].set_aspect('auto')\n","ax[2].set_title('Предсказание вероятности по каждому классу жеста')\n","ax[2].set_yticks(\n","    np.arange(9),\n","    ['Open', 'Pinky', 'Ring', 'Middle', 'Pistol', 'Index', 'Thumb', 'OK', 'Grab']\n",")\n","\n","ax[3].plot(y_pred_train_nn[id].argmax(axis=-1))\n","ax[3].set_aspect('auto')\n","ax[3].set_title('Предсказание класса жеста моделью')\n","ax[3].set_yticks(\n","    np.arange(9),\n","    ['Open', 'Pinky', 'Ring', 'Middle', 'Pistol', 'Index', 'Thumb', 'OK', 'Grab']\n",")\n","ax[3].set_xlabel('Время')\n","\n","plt.suptitle(f'Рис. {plot_counter}'+' - наблюдение ' + str(id), y=-0.01, fontsize=16)\n","\n","plt.tight_layout()\n","\n","plt.gcf()\n","\n","\n","    \n","plt.show()\n"]},{"cell_type":"markdown","id":"57cf9de5-5895-470a-93d5-9cc776747ef3","metadata":{"id":"57cf9de5-5895-470a-93d5-9cc776747ef3"},"source":["### Интерпретация графиков\n","\n","График 1 - это данные зафиксированные оптомиографическими датчиками. График 2 подача команды на совершение жеста для пилота. Как можно видеть есть некоторый временной лаг, объясняемый временем реакции.\n","\n","График 3 - это предсказания модели. График 4 - это фактическое движение, на тестовых данных именно оно будет использоваться для скоринга."]},{"cell_type":"markdown","id":"3eb9cbaf-7c94-4a41-a8db-7f4d5b4d75c4","metadata":{"id":"3eb9cbaf-7c94-4a41-a8db-7f4d5b4d75c4"},"source":["### Model predict"]},{"cell_type":"code","execution_count":38,"id":"af2b30c1-d9e7-43be-bfd9-a0dd59cc7ada","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"af2b30c1-d9e7-43be-bfd9-a0dd59cc7ada","outputId":"914ac0d8-59a3-40af-f723-9f6ae988ce3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 8ms/step\n","(54, 100)\n"]},{"data":{"text/plain":["array([[4, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 7, 7, 7],\n","       [7, 7, 7, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["y_pred_nn = model_baseline.predict(X_test_nn).argmax(axis=-1)\n","\n","print(y_pred_nn.shape)\n","y_pred_nn"]},{"cell_type":"code","execution_count":39,"id":"ce4dd9ca-3f63-4e12-8341-393bd827662e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ce4dd9ca-3f63-4e12-8341-393bd827662e","outputId":"48ca0526-647e-46d9-8543-afce5751d0bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5400,)\n"]},{"data":{"text/plain":["array([4, 0, 0, ..., 0, 0, 0], dtype=int64)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = np.concatenate([arr for arr in y_pred_nn])\n","\n","print(y_pred.shape)\n","y_pred"]},{"cell_type":"code","execution_count":40,"id":"fbaa020e-9f46-4559-9b4d-f28dec85d5cc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"fbaa020e-9f46-4559-9b4d-f28dec85d5cc","outputId":"a41a858e-2932-4ea7-fa2c-11fe3a8cc1bf"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sample-timestep</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>323-0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>323-1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>323-2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>323-3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5396</th>\n","      <td>376-96</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5397</th>\n","      <td>376-97</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5398</th>\n","      <td>376-98</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5399</th>\n","      <td>376-99</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5400 rows × 2 columns</p>\n","</div>"],"text/plain":["     sample-timestep  class\n","0              323-0      4\n","1              323-1      0\n","2              323-2      0\n","3              323-3      0\n","...              ...    ...\n","5396          376-96      0\n","5397          376-97      0\n","5398          376-98      0\n","5399          376-99      0\n","\n","[5400 rows x 2 columns]"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["y_test = pd.read_csv(os.path.join(PATH, './sample_submission.csv'))\n","y_test['class'] = y_pred\n","y_test.to_csv('./y_test_2rnn_sigmoid_predicted.csv', index=False)\n","y_test"]},{"cell_type":"code","execution_count":41,"id":"66005503-0cb3-4b22-80d8-49478f03a6e5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66005503-0cb3-4b22-80d8-49478f03a6e5","outputId":"6018637c-5483-4ee1-85a7-59b26bb90242"},"outputs":[{"data":{"text/plain":["0    3451\n","5     479\n","2     288\n","3     273\n","6     271\n","8     267\n","1     196\n","4     108\n","7      67\n","Name: class, dtype: int64"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["y_test['class'].value_counts()"]},{"cell_type":"markdown","id":"4OE-LM-Wq5U1","metadata":{"id":"4OE-LM-Wq5U1"},"source":["## Model LSTM"]},{"cell_type":"code","execution_count":43,"id":"2fV1IGucSEQD","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2fV1IGucSEQD","outputId":"a7d506be-7f7e-4157-a15e-cc4e1bd09836"},"outputs":[{"name":"stdout","output_type":"stream","text":["(323, 100, 40) (323, 100, 9)\n","(54, 100, 40)\n"]}],"source":["# Подготовка данных для подачи в модель\n","X_train_nn = X_train.swapaxes(1, 2)\n","X_test_nn = X_test.swapaxes(1, 2)\n","y_train_nn = tf.keras.utils.to_categorical(y_train_ch)\n","\n","print(X_train_nn.shape, y_train_nn.shape)\n","print(X_test_nn.shape)"]},{"cell_type":"code","execution_count":44,"id":"-rD-i2liSEQF","metadata":{"id":"-rD-i2liSEQF"},"outputs":[],"source":["# Функция для расчета метрики f1_score \n","# Примечание: Metrics have been removed from Keras core on 2.0 version\n","# https://stackoverflow.com/questions/66554207/calculating-micro-f-1-score-in-keras\n","\n","def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"\n","        Recall metric.\n","        Only computes a batch-wise average of recall.\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"\n","        Precision metric.\n","        Only computes a batch-wise average of precision.\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))"]},{"cell_type":"markdown","id":"KxtPmHy4tq9u","metadata":{"id":"KxtPmHy4tq9u"},"source":["В baseline было предложено использовать нейронную сеть с двумя слоями SimpleRNN,  На baseline, как и ожидалось был получен довольно низкий скор по метрике f1.  \n","Для получения лучшего скора и предсказания модели на тестовых данных была собрана модель из 4-х последовательных слоев LSTM (встроенные в Keras слои рекуррентной нейронной сети, предназначенной для предсказания данных временных рядов), одного полносвязанного слоя с функцией активации 'relu' и выходного слоя с функцией активации 'softmax' (для многоклассовой классификации). В качестве loss-функции выбрана \"categorical_crossentropy\" и optimizer='Adam'. Между выходным и полносвязным слоями добавлены слои BatchNormalization (для ускорения обучения модели и лучшей стабильности) и Dropout (для исключения переобучения).  \n","При обучении использовались callbacks: для сохранения лучшего результата, постепенного уменьшения learning rate (если не растет f1-score) и остановки обучения в случае длительного отсутствия улучшения рассматриваемой метрики."]},{"cell_type":"code","execution_count":63,"id":"PUQjFJchSEQG","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PUQjFJchSEQG","outputId":"d26852f0-c145-43a9-9e59-acdd6f6f79a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"Model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 100, 40)]    0           []                               \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 100, 100),   56400       ['input_1[0][0]']                \n","                                 (None, 100),                                                     \n","                                 (None, 100)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, 100, 100),   80400       ['lstm[0][0]',                   \n","                                 (None, 100),                     'lstm[0][1]',                   \n","                                 (None, 100)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," lstm_2 (LSTM)                  [(None, 100, 100),   80400       ['lstm_1[0][0]',                 \n","                                 (None, 100),                     'lstm_1[0][1]',                 \n","                                 (None, 100)]                     'lstm_1[0][2]']                 \n","                                                                                                  \n"," lstm_3 (LSTM)                  (None, 100, 100)     80400       ['lstm_2[0][0]',                 \n","                                                                  'lstm_2[0][1]',                 \n","                                                                  'lstm_2[0][2]']                 \n","                                                                                                  \n"," dense (Dense)                  (None, 100, 256)     25856       ['lstm_3[0][0]']                 \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 100, 256)    1024        ['dense[0][0]']                  \n"," alization)                                                                                       \n","                                                                                                  \n"," dropout (Dropout)              (None, 100, 256)     0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," dense_1 (Dense)                (None, 100, 9)       2313        ['dropout[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 326,793\n","Trainable params: 326,281\n","Non-trainable params: 512\n","__________________________________________________________________________________________________\n"]}],"source":["# удаляем предыдущую модель (если был подбор гиперпараметров) и очищаем память\n","tf.keras.backend.clear_session()\n","\n","# входной слой\n","input_channels = x = tf.keras.layers.Input(\n","    (X_train.shape[2], X_train.shape[1]),\n",")\n","\n","\n","x = tf.keras.layers.LSTM(100, return_sequences=True, return_state=True)(x) \n","x = tf.keras.layers.LSTM(100, return_sequences=True, return_state=True)(x)  \n","x = tf.keras.layers.LSTM(100, return_sequences=True, return_state=True)(x)  \n","x = tf.keras.layers.LSTM(100, return_sequences=True)(x)\n","\n","x = tf.keras.layers.Dense(256, activation='relu')(x)\n","x = tf.keras.layers.BatchNormalization()(x)\n","x = tf.keras.layers.Dropout(0.5)(x)\n","\n","\n","output = tf.keras.layers.Dense(units=9, activation='softmax')(x) #activation=tf.keras.layers.Softmax(axis=-1)\n","\n","model = tf.keras.Model(\n","    inputs=input_channels,\n","    outputs=output,\n","    name=\"Model\"\n",")\n","\n","model.compile(\n","    loss=\"categorical_crossentropy\",\n","    metrics=[f1],\n","    optimizer=tf.keras.optimizers.Adam(), # learning_rate=1e-2\n",")\n","model.summary()\n","\n","# Callbacks that used for training model\n","def callbacks(lr):\n","    checkpoint = ModelCheckpoint(PATH_BEST_MODEL+'best_model.hdf5', monitor='val_f1', \n","                                 verbose=1, mode='max', save_best_only=True)\n","    earlystop = EarlyStopping(monitor='val_f1', mode='max', patience=300, restore_best_weights=True)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_f1', mode='max', factor=0.9, patience=10, verbose=1, \n","                                  min_lr=lr/10000)\n","    return [checkpoint, earlystop, reduce_lr]\n","\n","callbacks_list = callbacks(lr=0.001)"]},{"cell_type":"code","execution_count":77,"id":"k5DPKqFYSEQH","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":976},"id":"k5DPKqFYSEQH","outputId":"ec1edcf7-1aa0-4924-8297-2d074aaaa622"},"outputs":[{"name":"stdout","output_type":"stream","text":["You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"]}],"source":["tf.keras.utils.plot_model(model, show_shapes=True)"]},{"cell_type":"markdown","id":"cf266487-5058-4739-aa11-82edeeb8c6cb","metadata":{"id":"cf266487-5058-4739-aa11-82edeeb8c6cb"},"source":["### Model train"]},{"cell_type":"code","execution_count":64,"id":"De33EFIbSEQI","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"De33EFIbSEQI","outputId":"ab20c649-6088-4533-c6ba-af51718f896e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1500\n","10/10 [==============================] - ETA: 0s - loss: 1.9050 - f1: 0.2861\n","Epoch 1: val_f1 improved from -inf to 0.00000, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 10s 428ms/step - loss: 1.9050 - f1: 0.2861 - val_loss: 1.9690 - val_f1: 0.0000e+00 - lr: 0.0010\n","Epoch 2/1500\n","10/10 [==============================] - ETA: 0s - loss: 1.1140 - f1: 0.6494\n","Epoch 2: val_f1 did not improve from 0.00000\n","10/10 [==============================] - 2s 244ms/step - loss: 1.1140 - f1: 0.6494 - val_loss: 1.7681 - val_f1: 0.0000e+00 - lr: 0.0010\n","Epoch 3/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.7498 - f1: 0.7796\n","Epoch 3: val_f1 did not improve from 0.00000\n","10/10 [==============================] - 3s 251ms/step - loss: 0.7498 - f1: 0.7796 - val_loss: 1.7030 - val_f1: 0.0000e+00 - lr: 0.0010\n","Epoch 4/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.6004 - f1: 0.7817\n","Epoch 4: val_f1 did not improve from 0.00000\n","10/10 [==============================] - 2s 237ms/step - loss: 0.6004 - f1: 0.7817 - val_loss: 1.6171 - val_f1: 0.0000e+00 - lr: 0.0010\n","Epoch 5/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.5691 - f1: 0.7878\n","Epoch 5: val_f1 did not improve from 0.00000\n","10/10 [==============================] - 2s 240ms/step - loss: 0.5691 - f1: 0.7878 - val_loss: 1.4830 - val_f1: 0.0000e+00 - lr: 0.0010\n","Epoch 6/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.5228 - f1: 0.8348\n","Epoch 6: val_f1 did not improve from 0.00000\n","10/10 [==============================] - 2s 240ms/step - loss: 0.5228 - f1: 0.8348 - val_loss: 1.4382 - val_f1: 0.0000e+00 - lr: 0.0010\n","Epoch 7/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.5189 - f1: 0.8422\n","Epoch 7: val_f1 did not improve from 0.00000\n","10/10 [==============================] - 2s 236ms/step - loss: 0.5189 - f1: 0.8422 - val_loss: 1.4439 - val_f1: 0.0000e+00 - lr: 0.0010\n","Epoch 8/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4423 - f1: 0.8388\n","Epoch 8: val_f1 improved from 0.00000 to 0.00559, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 247ms/step - loss: 0.4423 - f1: 0.8388 - val_loss: 1.4000 - val_f1: 0.0056 - lr: 0.0010\n","Epoch 9/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4830 - f1: 0.7894\n","Epoch 9: val_f1 improved from 0.00559 to 0.07624, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 3s 252ms/step - loss: 0.4830 - f1: 0.7894 - val_loss: 1.3873 - val_f1: 0.0762 - lr: 0.0010\n","Epoch 10/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4760 - f1: 0.8262\n","Epoch 10: val_f1 improved from 0.07624 to 0.20048, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 244ms/step - loss: 0.4760 - f1: 0.8262 - val_loss: 1.3052 - val_f1: 0.2005 - lr: 0.0010\n","Epoch 11/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4172 - f1: 0.8522\n","Epoch 11: val_f1 improved from 0.20048 to 0.25126, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 245ms/step - loss: 0.4172 - f1: 0.8522 - val_loss: 1.3319 - val_f1: 0.2513 - lr: 0.0010\n","Epoch 12/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4420 - f1: 0.8313\n","Epoch 12: val_f1 improved from 0.25126 to 0.76439, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 243ms/step - loss: 0.4420 - f1: 0.8313 - val_loss: 1.1836 - val_f1: 0.7644 - lr: 0.0010\n","Epoch 13/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4460 - f1: 0.8483\n","Epoch 13: val_f1 did not improve from 0.76439\n","10/10 [==============================] - 2s 243ms/step - loss: 0.4460 - f1: 0.8483 - val_loss: 1.2733 - val_f1: 0.7608 - lr: 0.0010\n","Epoch 14/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4281 - f1: 0.8578\n","Epoch 14: val_f1 did not improve from 0.76439\n","10/10 [==============================] - 2s 238ms/step - loss: 0.4281 - f1: 0.8578 - val_loss: 1.2018 - val_f1: 0.4768 - lr: 0.0010\n","Epoch 15/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3977 - f1: 0.8690\n","Epoch 15: val_f1 did not improve from 0.76439\n","10/10 [==============================] - 2s 244ms/step - loss: 0.3977 - f1: 0.8690 - val_loss: 1.2427 - val_f1: 0.4963 - lr: 0.0010\n","Epoch 16/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4738 - f1: 0.8467\n","Epoch 16: val_f1 did not improve from 0.76439\n","10/10 [==============================] - 2s 239ms/step - loss: 0.4738 - f1: 0.8467 - val_loss: 1.1241 - val_f1: 0.7586 - lr: 0.0010\n","Epoch 17/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.5427 - f1: 0.8158\n","Epoch 17: val_f1 did not improve from 0.76439\n","10/10 [==============================] - 2s 242ms/step - loss: 0.5427 - f1: 0.8158 - val_loss: 1.1663 - val_f1: 0.7622 - lr: 0.0010\n","Epoch 18/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4740 - f1: 0.8277\n","Epoch 18: val_f1 did not improve from 0.76439\n","10/10 [==============================] - 2s 239ms/step - loss: 0.4740 - f1: 0.8277 - val_loss: 1.1105 - val_f1: 0.7601 - lr: 0.0010\n","Epoch 19/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4190 - f1: 0.8700\n","Epoch 19: val_f1 improved from 0.76439 to 0.76575, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 244ms/step - loss: 0.4190 - f1: 0.8700 - val_loss: 1.0917 - val_f1: 0.7658 - lr: 0.0010\n","Epoch 20/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4269 - f1: 0.8599\n","Epoch 20: val_f1 did not improve from 0.76575\n","10/10 [==============================] - 2s 241ms/step - loss: 0.4269 - f1: 0.8599 - val_loss: 1.1089 - val_f1: 0.7602 - lr: 0.0010\n","Epoch 21/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3511 - f1: 0.8507\n","Epoch 21: val_f1 did not improve from 0.76575\n","10/10 [==============================] - 2s 239ms/step - loss: 0.3511 - f1: 0.8507 - val_loss: 0.9969 - val_f1: 0.7598 - lr: 0.0010\n","Epoch 22/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3460 - f1: 0.8899\n","Epoch 22: val_f1 did not improve from 0.76575\n","10/10 [==============================] - 2s 238ms/step - loss: 0.3460 - f1: 0.8899 - val_loss: 0.9773 - val_f1: 0.7415 - lr: 0.0010\n","Epoch 23/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3037 - f1: 0.9017\n","Epoch 23: val_f1 improved from 0.76575 to 0.78147, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 245ms/step - loss: 0.3037 - f1: 0.9017 - val_loss: 0.8910 - val_f1: 0.7815 - lr: 0.0010\n","Epoch 24/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2556 - f1: 0.9245\n","Epoch 24: val_f1 did not improve from 0.78147\n","10/10 [==============================] - 2s 236ms/step - loss: 0.2556 - f1: 0.9245 - val_loss: 0.8152 - val_f1: 0.7774 - lr: 0.0010\n","Epoch 25/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2961 - f1: 0.9073\n","Epoch 25: val_f1 did not improve from 0.78147\n","10/10 [==============================] - 2s 232ms/step - loss: 0.2961 - f1: 0.9073 - val_loss: 0.9289 - val_f1: 0.7721 - lr: 0.0010\n","Epoch 26/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4237 - f1: 0.8491\n","Epoch 26: val_f1 did not improve from 0.78147\n","10/10 [==============================] - 2s 240ms/step - loss: 0.4237 - f1: 0.8491 - val_loss: 0.8976 - val_f1: 0.7661 - lr: 0.0010\n","Epoch 27/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4789 - f1: 0.8440\n","Epoch 27: val_f1 did not improve from 0.78147\n","10/10 [==============================] - 2s 238ms/step - loss: 0.4789 - f1: 0.8440 - val_loss: 0.8901 - val_f1: 0.7719 - lr: 0.0010\n","Epoch 28/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4088 - f1: 0.8576\n","Epoch 28: val_f1 improved from 0.78147 to 0.80125, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 247ms/step - loss: 0.4088 - f1: 0.8576 - val_loss: 0.7847 - val_f1: 0.8013 - lr: 0.0010\n","Epoch 29/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3447 - f1: 0.8657\n","Epoch 29: val_f1 did not improve from 0.80125\n","10/10 [==============================] - 2s 242ms/step - loss: 0.3447 - f1: 0.8657 - val_loss: 0.9114 - val_f1: 0.7021 - lr: 0.0010\n","Epoch 30/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3650 - f1: 0.8552\n","Epoch 30: val_f1 did not improve from 0.80125\n","10/10 [==============================] - 2s 243ms/step - loss: 0.3650 - f1: 0.8552 - val_loss: 0.8655 - val_f1: 0.7417 - lr: 0.0010\n","Epoch 31/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4574 - f1: 0.8352\n","Epoch 31: val_f1 did not improve from 0.80125\n","10/10 [==============================] - 2s 244ms/step - loss: 0.4574 - f1: 0.8352 - val_loss: 0.7663 - val_f1: 0.7840 - lr: 0.0010\n","Epoch 32/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4523 - f1: 0.8537\n","Epoch 32: val_f1 did not improve from 0.80125\n","10/10 [==============================] - 2s 241ms/step - loss: 0.4523 - f1: 0.8537 - val_loss: 0.7733 - val_f1: 0.7911 - lr: 0.0010\n","Epoch 33/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3714 - f1: 0.8729\n","Epoch 33: val_f1 improved from 0.80125 to 0.80132, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 249ms/step - loss: 0.3714 - f1: 0.8729 - val_loss: 0.8132 - val_f1: 0.8013 - lr: 0.0010\n","Epoch 34/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2999 - f1: 0.8835\n","Epoch 34: val_f1 did not improve from 0.80132\n","10/10 [==============================] - 2s 245ms/step - loss: 0.2999 - f1: 0.8835 - val_loss: 0.7194 - val_f1: 0.7934 - lr: 0.0010\n","Epoch 35/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3715 - f1: 0.8795\n","Epoch 35: val_f1 improved from 0.80132 to 0.80185, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 248ms/step - loss: 0.3715 - f1: 0.8795 - val_loss: 0.6773 - val_f1: 0.8018 - lr: 0.0010\n","Epoch 36/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3974 - f1: 0.8488\n","Epoch 36: val_f1 improved from 0.80185 to 0.86258, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 3s 251ms/step - loss: 0.3974 - f1: 0.8488 - val_loss: 0.6957 - val_f1: 0.8626 - lr: 0.0010\n","Epoch 37/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3307 - f1: 0.8782\n","Epoch 37: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 246ms/step - loss: 0.3307 - f1: 0.8782 - val_loss: 0.7553 - val_f1: 0.7456 - lr: 0.0010\n","Epoch 38/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4287 - f1: 0.8641\n","Epoch 38: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 243ms/step - loss: 0.4287 - f1: 0.8641 - val_loss: 0.6366 - val_f1: 0.7927 - lr: 0.0010\n","Epoch 39/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4376 - f1: 0.8253\n","Epoch 39: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 243ms/step - loss: 0.4376 - f1: 0.8253 - val_loss: 0.6909 - val_f1: 0.7827 - lr: 0.0010\n","Epoch 40/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4611 - f1: 0.8505\n","Epoch 40: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 244ms/step - loss: 0.4611 - f1: 0.8505 - val_loss: 0.7180 - val_f1: 0.8031 - lr: 0.0010\n","Epoch 41/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3987 - f1: 0.8588\n","Epoch 41: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 243ms/step - loss: 0.3987 - f1: 0.8588 - val_loss: 0.8190 - val_f1: 0.8012 - lr: 0.0010\n","Epoch 42/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3968 - f1: 0.8679\n","Epoch 42: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 241ms/step - loss: 0.3968 - f1: 0.8679 - val_loss: 0.7486 - val_f1: 0.8033 - lr: 0.0010\n","Epoch 43/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3577 - f1: 0.8837\n","Epoch 43: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 244ms/step - loss: 0.3577 - f1: 0.8837 - val_loss: 0.6542 - val_f1: 0.8191 - lr: 0.0010\n","Epoch 44/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3583 - f1: 0.8770\n","Epoch 44: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 243ms/step - loss: 0.3583 - f1: 0.8770 - val_loss: 0.7555 - val_f1: 0.7708 - lr: 0.0010\n","Epoch 45/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3622 - f1: 0.8726\n","Epoch 45: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 240ms/step - loss: 0.3622 - f1: 0.8726 - val_loss: 0.5299 - val_f1: 0.8462 - lr: 0.0010\n","Epoch 46/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3601 - f1: 0.8911\n","Epoch 46: val_f1 did not improve from 0.86258\n","\n","Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n","10/10 [==============================] - 2s 242ms/step - loss: 0.3601 - f1: 0.8911 - val_loss: 0.5147 - val_f1: 0.8262 - lr: 0.0010\n","Epoch 47/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4622 - f1: 0.8434\n","Epoch 47: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 241ms/step - loss: 0.4622 - f1: 0.8434 - val_loss: 0.6511 - val_f1: 0.7780 - lr: 9.0000e-04\n","Epoch 48/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4454 - f1: 0.8481\n","Epoch 48: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 242ms/step - loss: 0.4454 - f1: 0.8481 - val_loss: 0.7432 - val_f1: 0.7673 - lr: 9.0000e-04\n","Epoch 49/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3622 - f1: 0.8629\n","Epoch 49: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 242ms/step - loss: 0.3622 - f1: 0.8629 - val_loss: 0.5428 - val_f1: 0.8286 - lr: 9.0000e-04\n","Epoch 50/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4590 - f1: 0.8154\n","Epoch 50: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 2s 247ms/step - loss: 0.4590 - f1: 0.8154 - val_loss: 0.5458 - val_f1: 0.8033 - lr: 9.0000e-04\n","Epoch 51/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4000 - f1: 0.8777\n","Epoch 51: val_f1 did not improve from 0.86258\n","10/10 [==============================] - 3s 250ms/step - loss: 0.4000 - f1: 0.8777 - val_loss: 0.4043 - val_f1: 0.8612 - lr: 9.0000e-04\n","Epoch 52/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3455 - f1: 0.8370\n","Epoch 52: val_f1 improved from 0.86258 to 0.87710, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 249ms/step - loss: 0.3455 - f1: 0.8370 - val_loss: 0.5866 - val_f1: 0.8771 - lr: 9.0000e-04\n","Epoch 53/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4632 - f1: 0.8259\n","Epoch 53: val_f1 did not improve from 0.87710\n","10/10 [==============================] - 2s 248ms/step - loss: 0.4632 - f1: 0.8259 - val_loss: 0.7189 - val_f1: 0.8556 - lr: 9.0000e-04\n","Epoch 54/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3684 - f1: 0.8333\n","Epoch 54: val_f1 did not improve from 0.87710\n","10/10 [==============================] - 2s 237ms/step - loss: 0.3684 - f1: 0.8333 - val_loss: 0.5697 - val_f1: 0.7908 - lr: 9.0000e-04\n","Epoch 55/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4345 - f1: 0.8458\n","Epoch 55: val_f1 did not improve from 0.87710\n","10/10 [==============================] - 2s 239ms/step - loss: 0.4345 - f1: 0.8458 - val_loss: 0.4749 - val_f1: 0.8176 - lr: 9.0000e-04\n","Epoch 56/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3419 - f1: 0.8854\n","Epoch 56: val_f1 improved from 0.87710 to 0.88034, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 3s 254ms/step - loss: 0.3419 - f1: 0.8854 - val_loss: 0.3896 - val_f1: 0.8803 - lr: 9.0000e-04\n","Epoch 57/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3278 - f1: 0.8845\n","Epoch 57: val_f1 improved from 0.88034 to 0.89015, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 250ms/step - loss: 0.3278 - f1: 0.8845 - val_loss: 0.5568 - val_f1: 0.8901 - lr: 9.0000e-04\n","Epoch 58/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3831 - f1: 0.8582\n","Epoch 58: val_f1 improved from 0.89015 to 0.89479, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 250ms/step - loss: 0.3831 - f1: 0.8582 - val_loss: 0.4573 - val_f1: 0.8948 - lr: 9.0000e-04\n","Epoch 59/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3523 - f1: 0.8757\n","Epoch 59: val_f1 did not improve from 0.89479\n","10/10 [==============================] - 2s 245ms/step - loss: 0.3523 - f1: 0.8757 - val_loss: 0.6841 - val_f1: 0.8736 - lr: 9.0000e-04\n","Epoch 60/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3193 - f1: 0.8782\n","Epoch 60: val_f1 did not improve from 0.89479\n","10/10 [==============================] - 2s 238ms/step - loss: 0.3193 - f1: 0.8782 - val_loss: 0.5360 - val_f1: 0.8941 - lr: 9.0000e-04\n","Epoch 61/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3706 - f1: 0.8740\n","Epoch 61: val_f1 did not improve from 0.89479\n","10/10 [==============================] - 2s 239ms/step - loss: 0.3706 - f1: 0.8740 - val_loss: 0.7405 - val_f1: 0.8761 - lr: 9.0000e-04\n","Epoch 62/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3038 - f1: 0.8735\n","Epoch 62: val_f1 improved from 0.89479 to 0.91161, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 246ms/step - loss: 0.3038 - f1: 0.8735 - val_loss: 0.4788 - val_f1: 0.9116 - lr: 9.0000e-04\n","Epoch 63/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3393 - f1: 0.8777\n","Epoch 63: val_f1 did not improve from 0.91161\n","10/10 [==============================] - 2s 242ms/step - loss: 0.3393 - f1: 0.8777 - val_loss: 0.4194 - val_f1: 0.8832 - lr: 9.0000e-04\n","Epoch 64/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4360 - f1: 0.8256\n","Epoch 64: val_f1 did not improve from 0.91161\n","10/10 [==============================] - 2s 241ms/step - loss: 0.4360 - f1: 0.8256 - val_loss: 0.9034 - val_f1: 0.7656 - lr: 9.0000e-04\n","Epoch 65/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4279 - f1: 0.8521\n","Epoch 65: val_f1 did not improve from 0.91161\n","10/10 [==============================] - 2s 240ms/step - loss: 0.4279 - f1: 0.8521 - val_loss: 0.4185 - val_f1: 0.8636 - lr: 9.0000e-04\n","Epoch 66/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3821 - f1: 0.8444\n","Epoch 66: val_f1 did not improve from 0.91161\n","10/10 [==============================] - 2s 239ms/step - loss: 0.3821 - f1: 0.8444 - val_loss: 0.5541 - val_f1: 0.8742 - lr: 9.0000e-04\n","Epoch 67/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4063 - f1: 0.8638\n","Epoch 67: val_f1 did not improve from 0.91161\n","10/10 [==============================] - 2s 243ms/step - loss: 0.4063 - f1: 0.8638 - val_loss: 0.4921 - val_f1: 0.8089 - lr: 9.0000e-04\n","Epoch 68/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3358 - f1: 0.8909\n","Epoch 68: val_f1 improved from 0.91161 to 0.95695, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 248ms/step - loss: 0.3358 - f1: 0.8909 - val_loss: 0.2395 - val_f1: 0.9570 - lr: 9.0000e-04\n","Epoch 69/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3061 - f1: 0.8849\n","Epoch 69: val_f1 did not improve from 0.95695\n","10/10 [==============================] - 2s 249ms/step - loss: 0.3061 - f1: 0.8849 - val_loss: 0.3665 - val_f1: 0.9170 - lr: 9.0000e-04\n","Epoch 70/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2999 - f1: 0.8917\n","Epoch 70: val_f1 did not improve from 0.95695\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2999 - f1: 0.8917 - val_loss: 0.2736 - val_f1: 0.9293 - lr: 9.0000e-04\n","Epoch 71/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3237 - f1: 0.8618\n","Epoch 71: val_f1 improved from 0.95695 to 0.96603, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 247ms/step - loss: 0.3237 - f1: 0.8618 - val_loss: 0.2192 - val_f1: 0.9660 - lr: 9.0000e-04\n","Epoch 72/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2857 - f1: 0.9089\n","Epoch 72: val_f1 did not improve from 0.96603\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2857 - f1: 0.9089 - val_loss: 0.3235 - val_f1: 0.9443 - lr: 9.0000e-04\n","Epoch 73/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2704 - f1: 0.9118\n","Epoch 73: val_f1 improved from 0.96603 to 0.96814, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2704 - f1: 0.9118 - val_loss: 0.2199 - val_f1: 0.9681 - lr: 9.0000e-04\n","Epoch 74/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2625 - f1: 0.9019\n","Epoch 74: val_f1 did not improve from 0.96814\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2625 - f1: 0.9019 - val_loss: 0.2965 - val_f1: 0.9249 - lr: 9.0000e-04\n","Epoch 75/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3094 - f1: 0.8977\n","Epoch 75: val_f1 did not improve from 0.96814\n","10/10 [==============================] - 2s 240ms/step - loss: 0.3094 - f1: 0.8977 - val_loss: 0.2531 - val_f1: 0.9549 - lr: 9.0000e-04\n","Epoch 76/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3211 - f1: 0.8963\n","Epoch 76: val_f1 did not improve from 0.96814\n","10/10 [==============================] - 2s 238ms/step - loss: 0.3211 - f1: 0.8963 - val_loss: 0.1975 - val_f1: 0.9498 - lr: 9.0000e-04\n","Epoch 77/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2758 - f1: 0.9072\n","Epoch 77: val_f1 improved from 0.96814 to 0.96830, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 3s 256ms/step - loss: 0.2758 - f1: 0.9072 - val_loss: 0.2442 - val_f1: 0.9683 - lr: 9.0000e-04\n","Epoch 78/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2366 - f1: 0.9253\n","Epoch 78: val_f1 did not improve from 0.96830\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2366 - f1: 0.9253 - val_loss: 0.1763 - val_f1: 0.9526 - lr: 9.0000e-04\n","Epoch 79/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2649 - f1: 0.9189\n","Epoch 79: val_f1 did not improve from 0.96830\n","10/10 [==============================] - 2s 235ms/step - loss: 0.2649 - f1: 0.9189 - val_loss: 0.3566 - val_f1: 0.9402 - lr: 9.0000e-04\n","Epoch 80/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2701 - f1: 0.9109\n","Epoch 80: val_f1 did not improve from 0.96830\n","10/10 [==============================] - 2s 237ms/step - loss: 0.2701 - f1: 0.9109 - val_loss: 0.1503 - val_f1: 0.9612 - lr: 9.0000e-04\n","Epoch 81/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2866 - f1: 0.9187\n","Epoch 81: val_f1 improved from 0.96830 to 0.97764, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2866 - f1: 0.9187 - val_loss: 0.1996 - val_f1: 0.9776 - lr: 9.0000e-04\n","Epoch 82/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2598 - f1: 0.9140\n","Epoch 82: val_f1 did not improve from 0.97764\n","10/10 [==============================] - 2s 239ms/step - loss: 0.2598 - f1: 0.9140 - val_loss: 0.2593 - val_f1: 0.9440 - lr: 9.0000e-04\n","Epoch 83/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2708 - f1: 0.8957\n","Epoch 83: val_f1 did not improve from 0.97764\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2708 - f1: 0.8957 - val_loss: 0.3074 - val_f1: 0.9579 - lr: 9.0000e-04\n","Epoch 84/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3165 - f1: 0.8902\n","Epoch 84: val_f1 did not improve from 0.97764\n","10/10 [==============================] - 2s 239ms/step - loss: 0.3165 - f1: 0.8902 - val_loss: 0.3537 - val_f1: 0.8956 - lr: 9.0000e-04\n","Epoch 85/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2650 - f1: 0.9130\n","Epoch 85: val_f1 did not improve from 0.97764\n","10/10 [==============================] - 2s 236ms/step - loss: 0.2650 - f1: 0.9130 - val_loss: 0.2082 - val_f1: 0.9450 - lr: 9.0000e-04\n","Epoch 86/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2525 - f1: 0.9230\n","Epoch 86: val_f1 did not improve from 0.97764\n","10/10 [==============================] - 2s 235ms/step - loss: 0.2525 - f1: 0.9230 - val_loss: 0.1246 - val_f1: 0.9688 - lr: 9.0000e-04\n","Epoch 87/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2536 - f1: 0.9011\n","Epoch 87: val_f1 did not improve from 0.97764\n","10/10 [==============================] - 2s 235ms/step - loss: 0.2536 - f1: 0.9011 - val_loss: 0.1677 - val_f1: 0.9405 - lr: 9.0000e-04\n","Epoch 88/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2053 - f1: 0.9334\n","Epoch 88: val_f1 improved from 0.97764 to 0.98221, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2053 - f1: 0.9334 - val_loss: 0.1302 - val_f1: 0.9822 - lr: 9.0000e-04\n","Epoch 89/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2369 - f1: 0.9064\n","Epoch 89: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 237ms/step - loss: 0.2369 - f1: 0.9064 - val_loss: 0.1832 - val_f1: 0.9603 - lr: 9.0000e-04\n","Epoch 90/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3653 - f1: 0.8427\n","Epoch 90: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 234ms/step - loss: 0.3653 - f1: 0.8427 - val_loss: 0.3286 - val_f1: 0.8605 - lr: 9.0000e-04\n","Epoch 91/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4435 - f1: 0.8026\n","Epoch 91: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 237ms/step - loss: 0.4435 - f1: 0.8026 - val_loss: 0.4539 - val_f1: 0.8385 - lr: 9.0000e-04\n","Epoch 92/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4935 - f1: 0.8132\n","Epoch 92: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.4935 - f1: 0.8132 - val_loss: 1.1822 - val_f1: 0.4204 - lr: 9.0000e-04\n","Epoch 93/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4036 - f1: 0.8618\n","Epoch 93: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.4036 - f1: 0.8618 - val_loss: 4.6960 - val_f1: 0.2600 - lr: 9.0000e-04\n","Epoch 94/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4568 - f1: 0.8376\n","Epoch 94: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 246ms/step - loss: 0.4568 - f1: 0.8376 - val_loss: 1.2608 - val_f1: 0.2701 - lr: 9.0000e-04\n","Epoch 95/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3483 - f1: 0.8610\n","Epoch 95: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.3483 - f1: 0.8610 - val_loss: 0.5820 - val_f1: 0.7903 - lr: 9.0000e-04\n","Epoch 96/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3405 - f1: 0.8711\n","Epoch 96: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.3405 - f1: 0.8711 - val_loss: 0.9223 - val_f1: 0.4327 - lr: 9.0000e-04\n","Epoch 97/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2606 - f1: 0.9085\n","Epoch 97: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.2606 - f1: 0.9085 - val_loss: 0.3468 - val_f1: 0.9216 - lr: 9.0000e-04\n","Epoch 98/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2708 - f1: 0.8921\n","Epoch 98: val_f1 did not improve from 0.98221\n","\n","Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2708 - f1: 0.8921 - val_loss: 0.3512 - val_f1: 0.9514 - lr: 9.0000e-04\n","Epoch 99/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2721 - f1: 0.9057\n","Epoch 99: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2721 - f1: 0.9057 - val_loss: 0.5375 - val_f1: 0.9104 - lr: 8.1000e-04\n","Epoch 100/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2472 - f1: 0.9182\n","Epoch 100: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2472 - f1: 0.9182 - val_loss: 0.1945 - val_f1: 0.9753 - lr: 8.1000e-04\n","Epoch 101/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2658 - f1: 0.9210\n","Epoch 101: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2658 - f1: 0.9210 - val_loss: 0.3892 - val_f1: 0.9578 - lr: 8.1000e-04\n","Epoch 102/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2553 - f1: 0.9169\n","Epoch 102: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 236ms/step - loss: 0.2553 - f1: 0.9169 - val_loss: 0.2171 - val_f1: 0.9730 - lr: 8.1000e-04\n","Epoch 103/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2341 - f1: 0.9206\n","Epoch 103: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.2341 - f1: 0.9206 - val_loss: 0.2233 - val_f1: 0.9634 - lr: 8.1000e-04\n","Epoch 104/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2187 - f1: 0.9273\n","Epoch 104: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 237ms/step - loss: 0.2187 - f1: 0.9273 - val_loss: 0.2222 - val_f1: 0.9593 - lr: 8.1000e-04\n","Epoch 105/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2133 - f1: 0.9066\n","Epoch 105: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2133 - f1: 0.9066 - val_loss: 0.1589 - val_f1: 0.9735 - lr: 8.1000e-04\n","Epoch 106/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2224 - f1: 0.9214\n","Epoch 106: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.2224 - f1: 0.9214 - val_loss: 0.3890 - val_f1: 0.9517 - lr: 8.1000e-04\n","Epoch 107/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2519 - f1: 0.9143\n","Epoch 107: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.2519 - f1: 0.9143 - val_loss: 0.1571 - val_f1: 0.9787 - lr: 8.1000e-04\n","Epoch 108/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2358 - f1: 0.9147\n","Epoch 108: val_f1 did not improve from 0.98221\n","\n","Epoch 108: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n","10/10 [==============================] - 2s 239ms/step - loss: 0.2358 - f1: 0.9147 - val_loss: 0.1801 - val_f1: 0.9430 - lr: 8.1000e-04\n","Epoch 109/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2035 - f1: 0.9310\n","Epoch 109: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2035 - f1: 0.9310 - val_loss: 0.2244 - val_f1: 0.9706 - lr: 7.2900e-04\n","Epoch 110/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2002 - f1: 0.9364\n","Epoch 110: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.2002 - f1: 0.9364 - val_loss: 0.2177 - val_f1: 0.9745 - lr: 7.2900e-04\n","Epoch 111/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2022 - f1: 0.9015\n","Epoch 111: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2022 - f1: 0.9015 - val_loss: 0.2540 - val_f1: 0.9636 - lr: 7.2900e-04\n","Epoch 112/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2488 - f1: 0.9016\n","Epoch 112: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 237ms/step - loss: 0.2488 - f1: 0.9016 - val_loss: 1.0624 - val_f1: 0.8239 - lr: 7.2900e-04\n","Epoch 113/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4705 - f1: 0.8392\n","Epoch 113: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.4705 - f1: 0.8392 - val_loss: 0.4255 - val_f1: 0.9219 - lr: 7.2900e-04\n","Epoch 114/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4456 - f1: 0.8711\n","Epoch 114: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.4456 - f1: 0.8711 - val_loss: 0.4586 - val_f1: 0.8884 - lr: 7.2900e-04\n","Epoch 115/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4643 - f1: 0.8562\n","Epoch 115: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.4643 - f1: 0.8562 - val_loss: 0.9530 - val_f1: 0.6840 - lr: 7.2900e-04\n","Epoch 116/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4202 - f1: 0.8504\n","Epoch 116: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.4202 - f1: 0.8504 - val_loss: 0.7958 - val_f1: 0.2885 - lr: 7.2900e-04\n","Epoch 117/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3854 - f1: 0.8700\n","Epoch 117: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.3854 - f1: 0.8700 - val_loss: 0.4687 - val_f1: 0.9083 - lr: 7.2900e-04\n","Epoch 118/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4130 - f1: 0.8728\n","Epoch 118: val_f1 did not improve from 0.98221\n","\n","Epoch 118: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n","10/10 [==============================] - 2s 238ms/step - loss: 0.4130 - f1: 0.8728 - val_loss: 1.1917 - val_f1: 0.8501 - lr: 7.2900e-04\n","Epoch 119/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4339 - f1: 0.8636\n","Epoch 119: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.4339 - f1: 0.8636 - val_loss: 0.4687 - val_f1: 0.8951 - lr: 6.5610e-04\n","Epoch 120/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3742 - f1: 0.8663\n","Epoch 120: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.3742 - f1: 0.8663 - val_loss: 0.5656 - val_f1: 0.8533 - lr: 6.5610e-04\n","Epoch 121/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3757 - f1: 0.8713\n","Epoch 121: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.3757 - f1: 0.8713 - val_loss: 0.4830 - val_f1: 0.8766 - lr: 6.5610e-04\n","Epoch 122/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3671 - f1: 0.8581\n","Epoch 122: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.3671 - f1: 0.8581 - val_loss: 0.3902 - val_f1: 0.9049 - lr: 6.5610e-04\n","Epoch 123/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3797 - f1: 0.8718\n","Epoch 123: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.3797 - f1: 0.8718 - val_loss: 0.3580 - val_f1: 0.9141 - lr: 6.5610e-04\n","Epoch 124/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3526 - f1: 0.8753\n","Epoch 124: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.3526 - f1: 0.8753 - val_loss: 1.0890 - val_f1: 0.4842 - lr: 6.5610e-04\n","Epoch 125/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3623 - f1: 0.8721\n","Epoch 125: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.3623 - f1: 0.8721 - val_loss: 0.3422 - val_f1: 0.9261 - lr: 6.5610e-04\n","Epoch 126/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3880 - f1: 0.8691\n","Epoch 126: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.3880 - f1: 0.8691 - val_loss: 0.3093 - val_f1: 0.9233 - lr: 6.5610e-04\n","Epoch 127/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3644 - f1: 0.8787\n","Epoch 127: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.3644 - f1: 0.8787 - val_loss: 0.4683 - val_f1: 0.8986 - lr: 6.5610e-04\n","Epoch 128/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3130 - f1: 0.8611\n","Epoch 128: val_f1 did not improve from 0.98221\n","\n","Epoch 128: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n","10/10 [==============================] - 2s 243ms/step - loss: 0.3130 - f1: 0.8611 - val_loss: 0.2459 - val_f1: 0.9318 - lr: 6.5610e-04\n","Epoch 129/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3185 - f1: 0.8870\n","Epoch 129: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.3185 - f1: 0.8870 - val_loss: 0.2746 - val_f1: 0.9197 - lr: 5.9049e-04\n","Epoch 130/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4535 - f1: 0.8279\n","Epoch 130: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 245ms/step - loss: 0.4535 - f1: 0.8279 - val_loss: 0.6223 - val_f1: 0.8378 - lr: 5.9049e-04\n","Epoch 131/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4975 - f1: 0.8344\n","Epoch 131: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.4975 - f1: 0.8344 - val_loss: 0.3523 - val_f1: 0.9194 - lr: 5.9049e-04\n","Epoch 132/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4040 - f1: 0.8269\n","Epoch 132: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.4040 - f1: 0.8269 - val_loss: 0.4321 - val_f1: 0.9196 - lr: 5.9049e-04\n","Epoch 133/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3718 - f1: 0.8458\n","Epoch 133: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.3718 - f1: 0.8458 - val_loss: 0.4965 - val_f1: 0.8206 - lr: 5.9049e-04\n","Epoch 134/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4128 - f1: 0.8333\n","Epoch 134: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.4128 - f1: 0.8333 - val_loss: 0.6265 - val_f1: 0.7916 - lr: 5.9049e-04\n","Epoch 135/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3716 - f1: 0.8581\n","Epoch 135: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.3716 - f1: 0.8581 - val_loss: 0.5146 - val_f1: 0.8666 - lr: 5.9049e-04\n","Epoch 136/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3106 - f1: 0.8955\n","Epoch 136: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.3106 - f1: 0.8955 - val_loss: 0.7388 - val_f1: 0.8549 - lr: 5.9049e-04\n","Epoch 137/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3319 - f1: 0.8777\n","Epoch 137: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.3319 - f1: 0.8777 - val_loss: 0.3842 - val_f1: 0.9252 - lr: 5.9049e-04\n","Epoch 138/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2950 - f1: 0.9001\n","Epoch 138: val_f1 did not improve from 0.98221\n","\n","Epoch 138: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2950 - f1: 0.9001 - val_loss: 0.4327 - val_f1: 0.9076 - lr: 5.9049e-04\n","Epoch 139/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2804 - f1: 0.8723\n","Epoch 139: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2804 - f1: 0.8723 - val_loss: 0.3600 - val_f1: 0.9232 - lr: 5.3144e-04\n","Epoch 140/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2950 - f1: 0.8685\n","Epoch 140: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2950 - f1: 0.8685 - val_loss: 0.3789 - val_f1: 0.9164 - lr: 5.3144e-04\n","Epoch 141/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3955 - f1: 0.8542\n","Epoch 141: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.3955 - f1: 0.8542 - val_loss: 0.3907 - val_f1: 0.9065 - lr: 5.3144e-04\n","Epoch 142/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.4826 - f1: 0.8331\n","Epoch 142: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.4826 - f1: 0.8331 - val_loss: 0.4136 - val_f1: 0.9214 - lr: 5.3144e-04\n","Epoch 143/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3472 - f1: 0.8438\n","Epoch 143: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.3472 - f1: 0.8438 - val_loss: 0.2775 - val_f1: 0.9339 - lr: 5.3144e-04\n","Epoch 144/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3177 - f1: 0.8517\n","Epoch 144: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 247ms/step - loss: 0.3177 - f1: 0.8517 - val_loss: 0.2428 - val_f1: 0.9463 - lr: 5.3144e-04\n","Epoch 145/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3306 - f1: 0.8787\n","Epoch 145: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.3306 - f1: 0.8787 - val_loss: 0.5122 - val_f1: 0.8784 - lr: 5.3144e-04\n","Epoch 146/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3092 - f1: 0.8574\n","Epoch 146: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.3092 - f1: 0.8574 - val_loss: 0.2582 - val_f1: 0.9345 - lr: 5.3144e-04\n","Epoch 147/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3004 - f1: 0.8994\n","Epoch 147: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.3004 - f1: 0.8994 - val_loss: 0.2514 - val_f1: 0.9284 - lr: 5.3144e-04\n","Epoch 148/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2993 - f1: 0.8310\n","Epoch 148: val_f1 did not improve from 0.98221\n","\n","Epoch 148: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2993 - f1: 0.8310 - val_loss: 0.2816 - val_f1: 0.9120 - lr: 5.3144e-04\n","Epoch 149/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2898 - f1: 0.8831\n","Epoch 149: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2898 - f1: 0.8831 - val_loss: 0.4678 - val_f1: 0.6084 - lr: 4.7830e-04\n","Epoch 150/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2854 - f1: 0.8995\n","Epoch 150: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2854 - f1: 0.8995 - val_loss: 0.3938 - val_f1: 0.9096 - lr: 4.7830e-04\n","Epoch 151/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2908 - f1: 0.8980\n","Epoch 151: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2908 - f1: 0.8980 - val_loss: 0.5253 - val_f1: 0.9283 - lr: 4.7830e-04\n","Epoch 152/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2882 - f1: 0.8728\n","Epoch 152: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 246ms/step - loss: 0.2882 - f1: 0.8728 - val_loss: 0.3797 - val_f1: 0.9117 - lr: 4.7830e-04\n","Epoch 153/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2723 - f1: 0.8491\n","Epoch 153: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 3s 259ms/step - loss: 0.2723 - f1: 0.8491 - val_loss: 0.2391 - val_f1: 0.9407 - lr: 4.7830e-04\n","Epoch 154/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.5013 - f1: 0.8034\n","Epoch 154: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.5013 - f1: 0.8034 - val_loss: 0.6582 - val_f1: 0.8512 - lr: 4.7830e-04\n","Epoch 155/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3718 - f1: 0.8475\n","Epoch 155: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 245ms/step - loss: 0.3718 - f1: 0.8475 - val_loss: 0.7372 - val_f1: 0.8280 - lr: 4.7830e-04\n","Epoch 156/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3339 - f1: 0.8692\n","Epoch 156: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.3339 - f1: 0.8692 - val_loss: 0.6877 - val_f1: 0.8283 - lr: 4.7830e-04\n","Epoch 157/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2960 - f1: 0.8969\n","Epoch 157: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.2960 - f1: 0.8969 - val_loss: 0.4585 - val_f1: 0.8733 - lr: 4.7830e-04\n","Epoch 158/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2901 - f1: 0.8815\n","Epoch 158: val_f1 did not improve from 0.98221\n","\n","Epoch 158: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2901 - f1: 0.8815 - val_loss: 0.3525 - val_f1: 0.9141 - lr: 4.7830e-04\n","Epoch 159/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2623 - f1: 0.9059\n","Epoch 159: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2623 - f1: 0.9059 - val_loss: 0.2276 - val_f1: 0.9484 - lr: 4.3047e-04\n","Epoch 160/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2511 - f1: 0.8920\n","Epoch 160: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2511 - f1: 0.8920 - val_loss: 0.2456 - val_f1: 0.9496 - lr: 4.3047e-04\n","Epoch 161/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3102 - f1: 0.8977\n","Epoch 161: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.3102 - f1: 0.8977 - val_loss: 0.4705 - val_f1: 0.9318 - lr: 4.3047e-04\n","Epoch 162/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3016 - f1: 0.8718\n","Epoch 162: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.3016 - f1: 0.8718 - val_loss: 0.2409 - val_f1: 0.9501 - lr: 4.3047e-04\n","Epoch 163/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2998 - f1: 0.8804\n","Epoch 163: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2998 - f1: 0.8804 - val_loss: 0.2458 - val_f1: 0.9527 - lr: 4.3047e-04\n","Epoch 164/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2570 - f1: 0.9036\n","Epoch 164: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 245ms/step - loss: 0.2570 - f1: 0.9036 - val_loss: 0.3666 - val_f1: 0.9152 - lr: 4.3047e-04\n","Epoch 165/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2770 - f1: 0.9051\n","Epoch 165: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2770 - f1: 0.9051 - val_loss: 0.2561 - val_f1: 0.9406 - lr: 4.3047e-04\n","Epoch 166/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2700 - f1: 0.8948\n","Epoch 166: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2700 - f1: 0.8948 - val_loss: 0.2532 - val_f1: 0.9347 - lr: 4.3047e-04\n","Epoch 167/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3441 - f1: 0.8498\n","Epoch 167: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.3441 - f1: 0.8498 - val_loss: 0.7729 - val_f1: 0.8583 - lr: 4.3047e-04\n","Epoch 168/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3981 - f1: 0.8474\n","Epoch 168: val_f1 did not improve from 0.98221\n","\n","Epoch 168: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n","10/10 [==============================] - 2s 243ms/step - loss: 0.3981 - f1: 0.8474 - val_loss: 0.4551 - val_f1: 0.9141 - lr: 4.3047e-04\n","Epoch 169/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3254 - f1: 0.8790\n","Epoch 169: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.3254 - f1: 0.8790 - val_loss: 0.2610 - val_f1: 0.8703 - lr: 3.8742e-04\n","Epoch 170/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2923 - f1: 0.8750\n","Epoch 170: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2923 - f1: 0.8750 - val_loss: 0.2454 - val_f1: 0.9447 - lr: 3.8742e-04\n","Epoch 171/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3173 - f1: 0.8779\n","Epoch 171: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.3173 - f1: 0.8779 - val_loss: 0.2445 - val_f1: 0.9475 - lr: 3.8742e-04\n","Epoch 172/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2514 - f1: 0.8954\n","Epoch 172: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2514 - f1: 0.8954 - val_loss: 0.2536 - val_f1: 0.9479 - lr: 3.8742e-04\n","Epoch 173/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2603 - f1: 0.8701\n","Epoch 173: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2603 - f1: 0.8701 - val_loss: 0.2757 - val_f1: 0.9439 - lr: 3.8742e-04\n","Epoch 174/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2591 - f1: 0.8944\n","Epoch 174: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 250ms/step - loss: 0.2591 - f1: 0.8944 - val_loss: 0.2459 - val_f1: 0.9469 - lr: 3.8742e-04\n","Epoch 175/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2452 - f1: 0.8909\n","Epoch 175: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 245ms/step - loss: 0.2452 - f1: 0.8909 - val_loss: 0.2951 - val_f1: 0.9421 - lr: 3.8742e-04\n","Epoch 176/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2545 - f1: 0.8874\n","Epoch 176: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2545 - f1: 0.8874 - val_loss: 0.2463 - val_f1: 0.9340 - lr: 3.8742e-04\n","Epoch 177/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2457 - f1: 0.8877\n","Epoch 177: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2457 - f1: 0.8877 - val_loss: 0.2018 - val_f1: 0.9514 - lr: 3.8742e-04\n","Epoch 178/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2306 - f1: 0.9100\n","Epoch 178: val_f1 did not improve from 0.98221\n","\n","Epoch 178: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2306 - f1: 0.9100 - val_loss: 0.2071 - val_f1: 0.9534 - lr: 3.8742e-04\n","Epoch 179/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2358 - f1: 0.9128\n","Epoch 179: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2358 - f1: 0.9128 - val_loss: 0.1755 - val_f1: 0.9648 - lr: 3.4868e-04\n","Epoch 180/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2368 - f1: 0.8989\n","Epoch 180: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2368 - f1: 0.8989 - val_loss: 0.1928 - val_f1: 0.9593 - lr: 3.4868e-04\n","Epoch 181/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2382 - f1: 0.8936\n","Epoch 181: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2382 - f1: 0.8936 - val_loss: 0.1933 - val_f1: 0.9591 - lr: 3.4868e-04\n","Epoch 182/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2501 - f1: 0.9035\n","Epoch 182: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2501 - f1: 0.9035 - val_loss: 0.2961 - val_f1: 0.9317 - lr: 3.4868e-04\n","Epoch 183/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3029 - f1: 0.8970\n","Epoch 183: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.3029 - f1: 0.8970 - val_loss: 0.2032 - val_f1: 0.9553 - lr: 3.4868e-04\n","Epoch 184/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2458 - f1: 0.9025\n","Epoch 184: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2458 - f1: 0.9025 - val_loss: 0.1967 - val_f1: 0.9599 - lr: 3.4868e-04\n","Epoch 185/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2316 - f1: 0.9134\n","Epoch 185: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2316 - f1: 0.9134 - val_loss: 0.1834 - val_f1: 0.9653 - lr: 3.4868e-04\n","Epoch 186/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2263 - f1: 0.9161\n","Epoch 186: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2263 - f1: 0.9161 - val_loss: 0.1781 - val_f1: 0.9663 - lr: 3.4868e-04\n","Epoch 187/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2182 - f1: 0.9154\n","Epoch 187: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2182 - f1: 0.9154 - val_loss: 0.1815 - val_f1: 0.9647 - lr: 3.4868e-04\n","Epoch 188/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2469 - f1: 0.8656\n","Epoch 188: val_f1 did not improve from 0.98221\n","\n","Epoch 188: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2469 - f1: 0.8656 - val_loss: 0.2366 - val_f1: 0.9494 - lr: 3.4868e-04\n","Epoch 189/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2668 - f1: 0.8762\n","Epoch 189: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2668 - f1: 0.8762 - val_loss: 0.2447 - val_f1: 0.9549 - lr: 3.1381e-04\n","Epoch 190/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2889 - f1: 0.8810\n","Epoch 190: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 245ms/step - loss: 0.2889 - f1: 0.8810 - val_loss: 0.3921 - val_f1: 0.9140 - lr: 3.1381e-04\n","Epoch 191/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2414 - f1: 0.9025\n","Epoch 191: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2414 - f1: 0.9025 - val_loss: 0.2021 - val_f1: 0.9524 - lr: 3.1381e-04\n","Epoch 192/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2409 - f1: 0.8925\n","Epoch 192: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2409 - f1: 0.8925 - val_loss: 0.1937 - val_f1: 0.9523 - lr: 3.1381e-04\n","Epoch 193/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2269 - f1: 0.9206\n","Epoch 193: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2269 - f1: 0.9206 - val_loss: 0.1844 - val_f1: 0.9596 - lr: 3.1381e-04\n","Epoch 194/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2299 - f1: 0.9114\n","Epoch 194: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2299 - f1: 0.9114 - val_loss: 0.1957 - val_f1: 0.9537 - lr: 3.1381e-04\n","Epoch 195/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2204 - f1: 0.9161\n","Epoch 195: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2204 - f1: 0.9161 - val_loss: 0.1796 - val_f1: 0.9618 - lr: 3.1381e-04\n","Epoch 196/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2042 - f1: 0.9165\n","Epoch 196: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2042 - f1: 0.9165 - val_loss: 0.1733 - val_f1: 0.9685 - lr: 3.1381e-04\n","Epoch 197/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2221 - f1: 0.8853\n","Epoch 197: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2221 - f1: 0.8853 - val_loss: 0.1658 - val_f1: 0.9667 - lr: 3.1381e-04\n","Epoch 198/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2396 - f1: 0.9095\n","Epoch 198: val_f1 did not improve from 0.98221\n","\n","Epoch 198: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n","10/10 [==============================] - 2s 239ms/step - loss: 0.2396 - f1: 0.9095 - val_loss: 0.2499 - val_f1: 0.9430 - lr: 3.1381e-04\n","Epoch 199/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2421 - f1: 0.9038\n","Epoch 199: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.2421 - f1: 0.9038 - val_loss: 0.1744 - val_f1: 0.9684 - lr: 2.8243e-04\n","Epoch 200/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2554 - f1: 0.9098\n","Epoch 200: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2554 - f1: 0.9098 - val_loss: 0.1745 - val_f1: 0.9690 - lr: 2.8243e-04\n","Epoch 201/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2474 - f1: 0.8936\n","Epoch 201: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2474 - f1: 0.8936 - val_loss: 0.1683 - val_f1: 0.9691 - lr: 2.8243e-04\n","Epoch 202/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2325 - f1: 0.9004\n","Epoch 202: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2325 - f1: 0.9004 - val_loss: 0.1707 - val_f1: 0.9645 - lr: 2.8243e-04\n","Epoch 203/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2185 - f1: 0.9151\n","Epoch 203: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2185 - f1: 0.9151 - val_loss: 0.1890 - val_f1: 0.9562 - lr: 2.8243e-04\n","Epoch 204/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2094 - f1: 0.9168\n","Epoch 204: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2094 - f1: 0.9168 - val_loss: 0.1655 - val_f1: 0.9671 - lr: 2.8243e-04\n","Epoch 205/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2222 - f1: 0.9048\n","Epoch 205: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 244ms/step - loss: 0.2222 - f1: 0.9048 - val_loss: 0.1601 - val_f1: 0.9739 - lr: 2.8243e-04\n","Epoch 206/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2113 - f1: 0.9111\n","Epoch 206: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2113 - f1: 0.9111 - val_loss: 0.1596 - val_f1: 0.9740 - lr: 2.8243e-04\n","Epoch 207/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2213 - f1: 0.8960\n","Epoch 207: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2213 - f1: 0.8960 - val_loss: 0.1703 - val_f1: 0.9678 - lr: 2.8243e-04\n","Epoch 208/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2401 - f1: 0.8903\n","Epoch 208: val_f1 did not improve from 0.98221\n","\n","Epoch 208: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2401 - f1: 0.8903 - val_loss: 0.2164 - val_f1: 0.9596 - lr: 2.8243e-04\n","Epoch 209/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2593 - f1: 0.8973\n","Epoch 209: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 246ms/step - loss: 0.2593 - f1: 0.8973 - val_loss: 0.2990 - val_f1: 0.9414 - lr: 2.5419e-04\n","Epoch 210/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2418 - f1: 0.8825\n","Epoch 210: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 3s 251ms/step - loss: 0.2418 - f1: 0.8825 - val_loss: 0.1931 - val_f1: 0.9527 - lr: 2.5419e-04\n","Epoch 211/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2203 - f1: 0.9046\n","Epoch 211: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2203 - f1: 0.9046 - val_loss: 0.1671 - val_f1: 0.9640 - lr: 2.5419e-04\n","Epoch 212/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.3161 - f1: 0.8638\n","Epoch 212: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.3161 - f1: 0.8638 - val_loss: 0.1652 - val_f1: 0.9626 - lr: 2.5419e-04\n","Epoch 213/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2482 - f1: 0.8737\n","Epoch 213: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2482 - f1: 0.8737 - val_loss: 0.2203 - val_f1: 0.9333 - lr: 2.5419e-04\n","Epoch 214/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2398 - f1: 0.8840\n","Epoch 214: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2398 - f1: 0.8840 - val_loss: 0.2170 - val_f1: 0.9539 - lr: 2.5419e-04\n","Epoch 215/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2263 - f1: 0.9077\n","Epoch 215: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2263 - f1: 0.9077 - val_loss: 0.1991 - val_f1: 0.9545 - lr: 2.5419e-04\n","Epoch 216/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2237 - f1: 0.9191\n","Epoch 216: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2237 - f1: 0.9191 - val_loss: 0.1647 - val_f1: 0.9646 - lr: 2.5419e-04\n","Epoch 217/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2096 - f1: 0.9126\n","Epoch 217: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2096 - f1: 0.9126 - val_loss: 0.1504 - val_f1: 0.9662 - lr: 2.5419e-04\n","Epoch 218/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2163 - f1: 0.9195\n","Epoch 218: val_f1 did not improve from 0.98221\n","\n","Epoch 218: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n","10/10 [==============================] - 2s 238ms/step - loss: 0.2163 - f1: 0.9195 - val_loss: 0.1835 - val_f1: 0.9542 - lr: 2.5419e-04\n","Epoch 219/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2121 - f1: 0.9167\n","Epoch 219: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2121 - f1: 0.9167 - val_loss: 0.1498 - val_f1: 0.9661 - lr: 2.2877e-04\n","Epoch 220/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1976 - f1: 0.9071\n","Epoch 220: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1976 - f1: 0.9071 - val_loss: 0.1723 - val_f1: 0.9694 - lr: 2.2877e-04\n","Epoch 221/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1957 - f1: 0.9169\n","Epoch 221: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1957 - f1: 0.9169 - val_loss: 0.1950 - val_f1: 0.9561 - lr: 2.2877e-04\n","Epoch 222/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2053 - f1: 0.9158\n","Epoch 222: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2053 - f1: 0.9158 - val_loss: 0.1580 - val_f1: 0.9668 - lr: 2.2877e-04\n","Epoch 223/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2009 - f1: 0.8978\n","Epoch 223: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.2009 - f1: 0.8978 - val_loss: 0.1547 - val_f1: 0.9697 - lr: 2.2877e-04\n","Epoch 224/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2025 - f1: 0.9200\n","Epoch 224: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.2025 - f1: 0.9200 - val_loss: 0.1534 - val_f1: 0.9676 - lr: 2.2877e-04\n","Epoch 225/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1948 - f1: 0.9239\n","Epoch 225: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1948 - f1: 0.9239 - val_loss: 0.1450 - val_f1: 0.9764 - lr: 2.2877e-04\n","Epoch 226/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1912 - f1: 0.9147\n","Epoch 226: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1912 - f1: 0.9147 - val_loss: 0.1416 - val_f1: 0.9770 - lr: 2.2877e-04\n","Epoch 227/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1995 - f1: 0.9057\n","Epoch 227: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1995 - f1: 0.9057 - val_loss: 0.1439 - val_f1: 0.9745 - lr: 2.2877e-04\n","Epoch 228/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1992 - f1: 0.9097\n","Epoch 228: val_f1 did not improve from 0.98221\n","\n","Epoch 228: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n","10/10 [==============================] - 3s 254ms/step - loss: 0.1992 - f1: 0.9097 - val_loss: 0.1720 - val_f1: 0.9543 - lr: 2.2877e-04\n","Epoch 229/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2143 - f1: 0.8993\n","Epoch 229: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.2143 - f1: 0.8993 - val_loss: 0.1518 - val_f1: 0.9723 - lr: 2.0589e-04\n","Epoch 230/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1904 - f1: 0.9079\n","Epoch 230: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1904 - f1: 0.9079 - val_loss: 0.1525 - val_f1: 0.9711 - lr: 2.0589e-04\n","Epoch 231/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1903 - f1: 0.9206\n","Epoch 231: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1903 - f1: 0.9206 - val_loss: 0.1888 - val_f1: 0.9589 - lr: 2.0589e-04\n","Epoch 232/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1922 - f1: 0.9267\n","Epoch 232: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1922 - f1: 0.9267 - val_loss: 0.1506 - val_f1: 0.9677 - lr: 2.0589e-04\n","Epoch 233/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1981 - f1: 0.9049\n","Epoch 233: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1981 - f1: 0.9049 - val_loss: 0.1466 - val_f1: 0.9747 - lr: 2.0589e-04\n","Epoch 234/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1948 - f1: 0.9139\n","Epoch 234: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1948 - f1: 0.9139 - val_loss: 0.1436 - val_f1: 0.9749 - lr: 2.0589e-04\n","Epoch 235/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1913 - f1: 0.9245\n","Epoch 235: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1913 - f1: 0.9245 - val_loss: 0.1499 - val_f1: 0.9730 - lr: 2.0589e-04\n","Epoch 236/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2005 - f1: 0.9146\n","Epoch 236: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2005 - f1: 0.9146 - val_loss: 0.1479 - val_f1: 0.9709 - lr: 2.0589e-04\n","Epoch 237/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1826 - f1: 0.9134\n","Epoch 237: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1826 - f1: 0.9134 - val_loss: 0.1440 - val_f1: 0.9740 - lr: 2.0589e-04\n","Epoch 238/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1785 - f1: 0.9210\n","Epoch 238: val_f1 did not improve from 0.98221\n","\n","Epoch 238: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1785 - f1: 0.9210 - val_loss: 0.1398 - val_f1: 0.9760 - lr: 2.0589e-04\n","Epoch 239/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1835 - f1: 0.9295\n","Epoch 239: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1835 - f1: 0.9295 - val_loss: 0.1337 - val_f1: 0.9752 - lr: 1.8530e-04\n","Epoch 240/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1878 - f1: 0.9253\n","Epoch 240: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1878 - f1: 0.9253 - val_loss: 0.1367 - val_f1: 0.9729 - lr: 1.8530e-04\n","Epoch 241/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1780 - f1: 0.9250\n","Epoch 241: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1780 - f1: 0.9250 - val_loss: 0.1435 - val_f1: 0.9747 - lr: 1.8530e-04\n","Epoch 242/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1845 - f1: 0.9288\n","Epoch 242: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1845 - f1: 0.9288 - val_loss: 0.1471 - val_f1: 0.9669 - lr: 1.8530e-04\n","Epoch 243/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1885 - f1: 0.9050\n","Epoch 243: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1885 - f1: 0.9050 - val_loss: 0.1502 - val_f1: 0.9617 - lr: 1.8530e-04\n","Epoch 244/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1799 - f1: 0.9190\n","Epoch 244: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1799 - f1: 0.9190 - val_loss: 0.1430 - val_f1: 0.9703 - lr: 1.8530e-04\n","Epoch 245/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1882 - f1: 0.9239\n","Epoch 245: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1882 - f1: 0.9239 - val_loss: 0.1476 - val_f1: 0.9740 - lr: 1.8530e-04\n","Epoch 246/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1898 - f1: 0.9261\n","Epoch 246: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1898 - f1: 0.9261 - val_loss: 0.1285 - val_f1: 0.9757 - lr: 1.8530e-04\n","Epoch 247/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1812 - f1: 0.9259\n","Epoch 247: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1812 - f1: 0.9259 - val_loss: 0.1396 - val_f1: 0.9661 - lr: 1.8530e-04\n","Epoch 248/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1814 - f1: 0.9230\n","Epoch 248: val_f1 did not improve from 0.98221\n","\n","Epoch 248: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1814 - f1: 0.9230 - val_loss: 0.1364 - val_f1: 0.9718 - lr: 1.8530e-04\n","Epoch 249/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1755 - f1: 0.8852\n","Epoch 249: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1755 - f1: 0.8852 - val_loss: 0.1368 - val_f1: 0.9651 - lr: 1.6677e-04\n","Epoch 250/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1817 - f1: 0.9251\n","Epoch 250: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1817 - f1: 0.9251 - val_loss: 0.1372 - val_f1: 0.9614 - lr: 1.6677e-04\n","Epoch 251/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1887 - f1: 0.9223\n","Epoch 251: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1887 - f1: 0.9223 - val_loss: 0.1768 - val_f1: 0.9605 - lr: 1.6677e-04\n","Epoch 252/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1729 - f1: 0.9207\n","Epoch 252: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1729 - f1: 0.9207 - val_loss: 0.1386 - val_f1: 0.9633 - lr: 1.6677e-04\n","Epoch 253/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1877 - f1: 0.9159\n","Epoch 253: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1877 - f1: 0.9159 - val_loss: 0.1460 - val_f1: 0.9613 - lr: 1.6677e-04\n","Epoch 254/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1962 - f1: 0.9016\n","Epoch 254: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1962 - f1: 0.9016 - val_loss: 0.1653 - val_f1: 0.9633 - lr: 1.6677e-04\n","Epoch 255/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2018 - f1: 0.9189\n","Epoch 255: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2018 - f1: 0.9189 - val_loss: 0.2315 - val_f1: 0.9494 - lr: 1.6677e-04\n","Epoch 256/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1778 - f1: 0.9294\n","Epoch 256: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1778 - f1: 0.9294 - val_loss: 0.1455 - val_f1: 0.9697 - lr: 1.6677e-04\n","Epoch 257/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1777 - f1: 0.9191\n","Epoch 257: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1777 - f1: 0.9191 - val_loss: 0.1556 - val_f1: 0.9569 - lr: 1.6677e-04\n","Epoch 258/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1757 - f1: 0.9302\n","Epoch 258: val_f1 did not improve from 0.98221\n","\n","Epoch 258: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1757 - f1: 0.9302 - val_loss: 0.1450 - val_f1: 0.9668 - lr: 1.6677e-04\n","Epoch 259/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1725 - f1: 0.9056\n","Epoch 259: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1725 - f1: 0.9056 - val_loss: 0.1538 - val_f1: 0.9609 - lr: 1.5009e-04\n","Epoch 260/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1684 - f1: 0.9376\n","Epoch 260: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1684 - f1: 0.9376 - val_loss: 0.1344 - val_f1: 0.9746 - lr: 1.5009e-04\n","Epoch 261/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1719 - f1: 0.9331\n","Epoch 261: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1719 - f1: 0.9331 - val_loss: 0.1215 - val_f1: 0.9763 - lr: 1.5009e-04\n","Epoch 262/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1637 - f1: 0.9246\n","Epoch 262: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1637 - f1: 0.9246 - val_loss: 0.1619 - val_f1: 0.9691 - lr: 1.5009e-04\n","Epoch 263/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2138 - f1: 0.9075\n","Epoch 263: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2138 - f1: 0.9075 - val_loss: 0.2478 - val_f1: 0.9377 - lr: 1.5009e-04\n","Epoch 264/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2118 - f1: 0.9101\n","Epoch 264: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2118 - f1: 0.9101 - val_loss: 0.2235 - val_f1: 0.9493 - lr: 1.5009e-04\n","Epoch 265/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2042 - f1: 0.9249\n","Epoch 265: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.2042 - f1: 0.9249 - val_loss: 0.1711 - val_f1: 0.9624 - lr: 1.5009e-04\n","Epoch 266/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1873 - f1: 0.9276\n","Epoch 266: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1873 - f1: 0.9276 - val_loss: 0.1616 - val_f1: 0.9660 - lr: 1.5009e-04\n","Epoch 267/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1811 - f1: 0.9284\n","Epoch 267: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1811 - f1: 0.9284 - val_loss: 0.1515 - val_f1: 0.9691 - lr: 1.5009e-04\n","Epoch 268/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1807 - f1: 0.9129\n","Epoch 268: val_f1 did not improve from 0.98221\n","\n","Epoch 268: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1807 - f1: 0.9129 - val_loss: 0.1423 - val_f1: 0.9742 - lr: 1.5009e-04\n","Epoch 269/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1768 - f1: 0.9277\n","Epoch 269: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 245ms/step - loss: 0.1768 - f1: 0.9277 - val_loss: 0.1491 - val_f1: 0.9712 - lr: 1.3509e-04\n","Epoch 270/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1747 - f1: 0.9203\n","Epoch 270: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1747 - f1: 0.9203 - val_loss: 0.1444 - val_f1: 0.9730 - lr: 1.3509e-04\n","Epoch 271/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1674 - f1: 0.9352\n","Epoch 271: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1674 - f1: 0.9352 - val_loss: 0.1386 - val_f1: 0.9728 - lr: 1.3509e-04\n","Epoch 272/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1673 - f1: 0.9306\n","Epoch 272: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1673 - f1: 0.9306 - val_loss: 0.1470 - val_f1: 0.9661 - lr: 1.3509e-04\n","Epoch 273/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1709 - f1: 0.9221\n","Epoch 273: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1709 - f1: 0.9221 - val_loss: 0.1407 - val_f1: 0.9653 - lr: 1.3509e-04\n","Epoch 274/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1651 - f1: 0.9375\n","Epoch 274: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1651 - f1: 0.9375 - val_loss: 0.1342 - val_f1: 0.9665 - lr: 1.3509e-04\n","Epoch 275/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1771 - f1: 0.9304\n","Epoch 275: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1771 - f1: 0.9304 - val_loss: 0.1292 - val_f1: 0.9724 - lr: 1.3509e-04\n","Epoch 276/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1671 - f1: 0.9141\n","Epoch 276: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1671 - f1: 0.9141 - val_loss: 0.1309 - val_f1: 0.9734 - lr: 1.3509e-04\n","Epoch 277/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1633 - f1: 0.9345\n","Epoch 277: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1633 - f1: 0.9345 - val_loss: 0.1268 - val_f1: 0.9749 - lr: 1.3509e-04\n","Epoch 278/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1633 - f1: 0.9372\n","Epoch 278: val_f1 did not improve from 0.98221\n","\n","Epoch 278: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1633 - f1: 0.9372 - val_loss: 0.1281 - val_f1: 0.9721 - lr: 1.3509e-04\n","Epoch 279/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1666 - f1: 0.9306\n","Epoch 279: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1666 - f1: 0.9306 - val_loss: 0.1374 - val_f1: 0.9628 - lr: 1.2158e-04\n","Epoch 280/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1658 - f1: 0.9362\n","Epoch 280: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1658 - f1: 0.9362 - val_loss: 0.1480 - val_f1: 0.9613 - lr: 1.2158e-04\n","Epoch 281/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1591 - f1: 0.9361\n","Epoch 281: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1591 - f1: 0.9361 - val_loss: 0.1264 - val_f1: 0.9763 - lr: 1.2158e-04\n","Epoch 282/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1989 - f1: 0.9331\n","Epoch 282: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1989 - f1: 0.9331 - val_loss: 0.1578 - val_f1: 0.9621 - lr: 1.2158e-04\n","Epoch 283/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1885 - f1: 0.9347\n","Epoch 283: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1885 - f1: 0.9347 - val_loss: 0.1380 - val_f1: 0.9643 - lr: 1.2158e-04\n","Epoch 284/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1656 - f1: 0.9288\n","Epoch 284: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1656 - f1: 0.9288 - val_loss: 0.1664 - val_f1: 0.9552 - lr: 1.2158e-04\n","Epoch 285/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1880 - f1: 0.9262\n","Epoch 285: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1880 - f1: 0.9262 - val_loss: 0.1672 - val_f1: 0.9633 - lr: 1.2158e-04\n","Epoch 286/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1795 - f1: 0.9321\n","Epoch 286: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1795 - f1: 0.9321 - val_loss: 0.1466 - val_f1: 0.9749 - lr: 1.2158e-04\n","Epoch 287/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1742 - f1: 0.9255\n","Epoch 287: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1742 - f1: 0.9255 - val_loss: 0.1333 - val_f1: 0.9675 - lr: 1.2158e-04\n","Epoch 288/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1665 - f1: 0.9291\n","Epoch 288: val_f1 did not improve from 0.98221\n","\n","Epoch 288: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1665 - f1: 0.9291 - val_loss: 0.1454 - val_f1: 0.9605 - lr: 1.2158e-04\n","Epoch 289/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1734 - f1: 0.9306\n","Epoch 289: val_f1 did not improve from 0.98221\n","10/10 [==============================] - 2s 245ms/step - loss: 0.1734 - f1: 0.9306 - val_loss: 0.1264 - val_f1: 0.9674 - lr: 1.0942e-04\n","Epoch 290/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1664 - f1: 0.9332\n","Epoch 290: val_f1 improved from 0.98221 to 0.98579, saving model to best_models\\best_model.hdf5\n","10/10 [==============================] - 2s 246ms/step - loss: 0.1664 - f1: 0.9332 - val_loss: 0.1115 - val_f1: 0.9858 - lr: 1.0942e-04\n","Epoch 291/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1542 - f1: 0.9392\n","Epoch 291: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1542 - f1: 0.9392 - val_loss: 0.1090 - val_f1: 0.9805 - lr: 1.0942e-04\n","Epoch 292/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1557 - f1: 0.9286\n","Epoch 292: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1557 - f1: 0.9286 - val_loss: 0.1115 - val_f1: 0.9849 - lr: 1.0942e-04\n","Epoch 293/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1626 - f1: 0.9340\n","Epoch 293: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1626 - f1: 0.9340 - val_loss: 0.1068 - val_f1: 0.9811 - lr: 1.0942e-04\n","Epoch 294/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1554 - f1: 0.9387\n","Epoch 294: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1554 - f1: 0.9387 - val_loss: 0.1083 - val_f1: 0.9804 - lr: 1.0942e-04\n","Epoch 295/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1657 - f1: 0.9396\n","Epoch 295: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1657 - f1: 0.9396 - val_loss: 0.1056 - val_f1: 0.9829 - lr: 1.0942e-04\n","Epoch 296/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1594 - f1: 0.9189\n","Epoch 296: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1594 - f1: 0.9189 - val_loss: 0.1183 - val_f1: 0.9776 - lr: 1.0942e-04\n","Epoch 297/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1501 - f1: 0.9177\n","Epoch 297: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1501 - f1: 0.9177 - val_loss: 0.1052 - val_f1: 0.9813 - lr: 1.0942e-04\n","Epoch 298/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1582 - f1: 0.9213\n","Epoch 298: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 246ms/step - loss: 0.1582 - f1: 0.9213 - val_loss: 0.1142 - val_f1: 0.9773 - lr: 1.0942e-04\n","Epoch 299/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1593 - f1: 0.9326\n","Epoch 299: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1593 - f1: 0.9326 - val_loss: 0.1173 - val_f1: 0.9726 - lr: 1.0942e-04\n","Epoch 300/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1618 - f1: 0.9336\n","Epoch 300: val_f1 did not improve from 0.98579\n","\n","Epoch 300: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1618 - f1: 0.9336 - val_loss: 0.1280 - val_f1: 0.9636 - lr: 1.0942e-04\n","Epoch 301/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1556 - f1: 0.9156\n","Epoch 301: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1556 - f1: 0.9156 - val_loss: 0.1315 - val_f1: 0.9607 - lr: 9.8477e-05\n","Epoch 302/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1565 - f1: 0.9234\n","Epoch 302: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1565 - f1: 0.9234 - val_loss: 0.1250 - val_f1: 0.9746 - lr: 9.8477e-05\n","Epoch 303/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1611 - f1: 0.9269\n","Epoch 303: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 3s 256ms/step - loss: 0.1611 - f1: 0.9269 - val_loss: 0.1232 - val_f1: 0.9724 - lr: 9.8477e-05\n","Epoch 304/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1521 - f1: 0.9276\n","Epoch 304: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 246ms/step - loss: 0.1521 - f1: 0.9276 - val_loss: 0.1273 - val_f1: 0.9635 - lr: 9.8477e-05\n","Epoch 305/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1598 - f1: 0.9388\n","Epoch 305: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1598 - f1: 0.9388 - val_loss: 0.1372 - val_f1: 0.9622 - lr: 9.8477e-05\n","Epoch 306/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1550 - f1: 0.9404\n","Epoch 306: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1550 - f1: 0.9404 - val_loss: 0.1175 - val_f1: 0.9713 - lr: 9.8477e-05\n","Epoch 307/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1650 - f1: 0.9424\n","Epoch 307: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1650 - f1: 0.9424 - val_loss: 0.1403 - val_f1: 0.9642 - lr: 9.8477e-05\n","Epoch 308/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1588 - f1: 0.9358\n","Epoch 308: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1588 - f1: 0.9358 - val_loss: 0.1282 - val_f1: 0.9649 - lr: 9.8477e-05\n","Epoch 309/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1876 - f1: 0.9394\n","Epoch 309: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1876 - f1: 0.9394 - val_loss: 0.1246 - val_f1: 0.9701 - lr: 9.8477e-05\n","Epoch 310/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2079 - f1: 0.9187\n","Epoch 310: val_f1 did not improve from 0.98579\n","\n","Epoch 310: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n","10/10 [==============================] - 2s 240ms/step - loss: 0.2079 - f1: 0.9187 - val_loss: 0.1537 - val_f1: 0.9571 - lr: 9.8477e-05\n","Epoch 311/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1945 - f1: 0.9351\n","Epoch 311: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1945 - f1: 0.9351 - val_loss: 0.1189 - val_f1: 0.9726 - lr: 8.8629e-05\n","Epoch 312/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1537 - f1: 0.9435\n","Epoch 312: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1537 - f1: 0.9435 - val_loss: 0.1271 - val_f1: 0.9700 - lr: 8.8629e-05\n","Epoch 313/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1499 - f1: 0.9448\n","Epoch 313: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1499 - f1: 0.9448 - val_loss: 0.1309 - val_f1: 0.9668 - lr: 8.8629e-05\n","Epoch 314/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1517 - f1: 0.9433\n","Epoch 314: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1517 - f1: 0.9433 - val_loss: 0.1212 - val_f1: 0.9655 - lr: 8.8629e-05\n","Epoch 315/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1407 - f1: 0.9532\n","Epoch 315: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1407 - f1: 0.9532 - val_loss: 0.1197 - val_f1: 0.9700 - lr: 8.8629e-05\n","Epoch 316/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1466 - f1: 0.9454\n","Epoch 316: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1466 - f1: 0.9454 - val_loss: 0.1223 - val_f1: 0.9691 - lr: 8.8629e-05\n","Epoch 317/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1502 - f1: 0.9429\n","Epoch 317: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1502 - f1: 0.9429 - val_loss: 0.1306 - val_f1: 0.9661 - lr: 8.8629e-05\n","Epoch 318/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1464 - f1: 0.9427\n","Epoch 318: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1464 - f1: 0.9427 - val_loss: 0.1270 - val_f1: 0.9702 - lr: 8.8629e-05\n","Epoch 319/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1536 - f1: 0.8994\n","Epoch 319: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1536 - f1: 0.8994 - val_loss: 0.1553 - val_f1: 0.9627 - lr: 8.8629e-05\n","Epoch 320/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1486 - f1: 0.9341\n","Epoch 320: val_f1 did not improve from 0.98579\n","\n","Epoch 320: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1486 - f1: 0.9341 - val_loss: 0.1611 - val_f1: 0.9631 - lr: 8.8629e-05\n","Epoch 321/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1403 - f1: 0.9509\n","Epoch 321: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1403 - f1: 0.9509 - val_loss: 0.1694 - val_f1: 0.9597 - lr: 7.9766e-05\n","Epoch 322/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1456 - f1: 0.9395\n","Epoch 322: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1456 - f1: 0.9395 - val_loss: 0.1544 - val_f1: 0.9629 - lr: 7.9766e-05\n","Epoch 323/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.2019 - f1: 0.9105\n","Epoch 323: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.2019 - f1: 0.9105 - val_loss: 0.2217 - val_f1: 0.9473 - lr: 7.9766e-05\n","Epoch 324/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1944 - f1: 0.8973\n","Epoch 324: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1944 - f1: 0.8973 - val_loss: 0.2510 - val_f1: 0.9545 - lr: 7.9766e-05\n","Epoch 325/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1789 - f1: 0.9284\n","Epoch 325: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1789 - f1: 0.9284 - val_loss: 0.1361 - val_f1: 0.9710 - lr: 7.9766e-05\n","Epoch 326/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1672 - f1: 0.9381\n","Epoch 326: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1672 - f1: 0.9381 - val_loss: 0.1243 - val_f1: 0.9728 - lr: 7.9766e-05\n","Epoch 327/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1631 - f1: 0.9157\n","Epoch 327: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1631 - f1: 0.9157 - val_loss: 0.1207 - val_f1: 0.9754 - lr: 7.9766e-05\n","Epoch 328/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1559 - f1: 0.8907\n","Epoch 328: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1559 - f1: 0.8907 - val_loss: 0.1431 - val_f1: 0.9667 - lr: 7.9766e-05\n","Epoch 329/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1561 - f1: 0.9238\n","Epoch 329: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1561 - f1: 0.9238 - val_loss: 0.1330 - val_f1: 0.9660 - lr: 7.9766e-05\n","Epoch 330/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1626 - f1: 0.8953\n","Epoch 330: val_f1 did not improve from 0.98579\n","\n","Epoch 330: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1626 - f1: 0.8953 - val_loss: 0.1416 - val_f1: 0.9665 - lr: 7.9766e-05\n","Epoch 331/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1643 - f1: 0.9321\n","Epoch 331: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1643 - f1: 0.9321 - val_loss: 0.1299 - val_f1: 0.9749 - lr: 7.1790e-05\n","Epoch 332/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1554 - f1: 0.9451\n","Epoch 332: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1554 - f1: 0.9451 - val_loss: 0.1333 - val_f1: 0.9689 - lr: 7.1790e-05\n","Epoch 333/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1539 - f1: 0.9452\n","Epoch 333: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1539 - f1: 0.9452 - val_loss: 0.1251 - val_f1: 0.9708 - lr: 7.1790e-05\n","Epoch 334/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1572 - f1: 0.9440\n","Epoch 334: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 245ms/step - loss: 0.1572 - f1: 0.9440 - val_loss: 0.1275 - val_f1: 0.9645 - lr: 7.1790e-05\n","Epoch 335/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1480 - f1: 0.9447\n","Epoch 335: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 245ms/step - loss: 0.1480 - f1: 0.9447 - val_loss: 0.1128 - val_f1: 0.9778 - lr: 7.1790e-05\n","Epoch 336/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1457 - f1: 0.9516\n","Epoch 336: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1457 - f1: 0.9516 - val_loss: 0.1215 - val_f1: 0.9682 - lr: 7.1790e-05\n","Epoch 337/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1473 - f1: 0.9378\n","Epoch 337: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1473 - f1: 0.9378 - val_loss: 0.1184 - val_f1: 0.9724 - lr: 7.1790e-05\n","Epoch 338/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1427 - f1: 0.9463\n","Epoch 338: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1427 - f1: 0.9463 - val_loss: 0.1285 - val_f1: 0.9656 - lr: 7.1790e-05\n","Epoch 339/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1508 - f1: 0.9476\n","Epoch 339: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1508 - f1: 0.9476 - val_loss: 0.1651 - val_f1: 0.9567 - lr: 7.1790e-05\n","Epoch 340/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1417 - f1: 0.9449\n","Epoch 340: val_f1 did not improve from 0.98579\n","\n","Epoch 340: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1417 - f1: 0.9449 - val_loss: 0.1158 - val_f1: 0.9764 - lr: 7.1790e-05\n","Epoch 341/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1462 - f1: 0.9451\n","Epoch 341: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1462 - f1: 0.9451 - val_loss: 0.1097 - val_f1: 0.9809 - lr: 6.4611e-05\n","Epoch 342/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1408 - f1: 0.9459\n","Epoch 342: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1408 - f1: 0.9459 - val_loss: 0.1294 - val_f1: 0.9656 - lr: 6.4611e-05\n","Epoch 343/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1468 - f1: 0.9498\n","Epoch 343: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1468 - f1: 0.9498 - val_loss: 0.1177 - val_f1: 0.9727 - lr: 6.4611e-05\n","Epoch 344/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1408 - f1: 0.9504\n","Epoch 344: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1408 - f1: 0.9504 - val_loss: 0.1260 - val_f1: 0.9690 - lr: 6.4611e-05\n","Epoch 345/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1368 - f1: 0.9490\n","Epoch 345: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1368 - f1: 0.9490 - val_loss: 0.1386 - val_f1: 0.9643 - lr: 6.4611e-05\n","Epoch 346/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1391 - f1: 0.9519\n","Epoch 346: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1391 - f1: 0.9519 - val_loss: 0.1410 - val_f1: 0.9675 - lr: 6.4611e-05\n","Epoch 347/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1444 - f1: 0.9531\n","Epoch 347: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1444 - f1: 0.9531 - val_loss: 0.1361 - val_f1: 0.9672 - lr: 6.4611e-05\n","Epoch 348/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1358 - f1: 0.9490\n","Epoch 348: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1358 - f1: 0.9490 - val_loss: 0.1411 - val_f1: 0.9675 - lr: 6.4611e-05\n","Epoch 349/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1446 - f1: 0.9456\n","Epoch 349: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1446 - f1: 0.9456 - val_loss: 0.1412 - val_f1: 0.9646 - lr: 6.4611e-05\n","Epoch 350/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1439 - f1: 0.9503\n","Epoch 350: val_f1 did not improve from 0.98579\n","\n","Epoch 350: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1439 - f1: 0.9503 - val_loss: 0.1552 - val_f1: 0.9633 - lr: 6.4611e-05\n","Epoch 351/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1421 - f1: 0.9488\n","Epoch 351: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1421 - f1: 0.9488 - val_loss: 0.1483 - val_f1: 0.9644 - lr: 5.8150e-05\n","Epoch 352/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1414 - f1: 0.9379\n","Epoch 352: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1414 - f1: 0.9379 - val_loss: 0.1395 - val_f1: 0.9643 - lr: 5.8150e-05\n","Epoch 353/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1340 - f1: 0.9440\n","Epoch 353: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1340 - f1: 0.9440 - val_loss: 0.1415 - val_f1: 0.9648 - lr: 5.8150e-05\n","Epoch 354/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1392 - f1: 0.9181\n","Epoch 354: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1392 - f1: 0.9181 - val_loss: 0.1546 - val_f1: 0.9633 - lr: 5.8150e-05\n","Epoch 355/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1381 - f1: 0.9392\n","Epoch 355: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1381 - f1: 0.9392 - val_loss: 0.1566 - val_f1: 0.9634 - lr: 5.8150e-05\n","Epoch 356/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1429 - f1: 0.9506\n","Epoch 356: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1429 - f1: 0.9506 - val_loss: 0.1369 - val_f1: 0.9649 - lr: 5.8150e-05\n","Epoch 357/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1447 - f1: 0.9381\n","Epoch 357: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1447 - f1: 0.9381 - val_loss: 0.1401 - val_f1: 0.9645 - lr: 5.8150e-05\n","Epoch 358/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1388 - f1: 0.9343\n","Epoch 358: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1388 - f1: 0.9343 - val_loss: 0.1413 - val_f1: 0.9652 - lr: 5.8150e-05\n","Epoch 359/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1425 - f1: 0.9478\n","Epoch 359: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1425 - f1: 0.9478 - val_loss: 0.1548 - val_f1: 0.9645 - lr: 5.8150e-05\n","Epoch 360/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1382 - f1: 0.9488\n","Epoch 360: val_f1 did not improve from 0.98579\n","\n","Epoch 360: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1382 - f1: 0.9488 - val_loss: 0.1464 - val_f1: 0.9645 - lr: 5.8150e-05\n","Epoch 361/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1430 - f1: 0.9218\n","Epoch 361: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1430 - f1: 0.9218 - val_loss: 0.1484 - val_f1: 0.9640 - lr: 5.2335e-05\n","Epoch 362/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1322 - f1: 0.9532\n","Epoch 362: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1322 - f1: 0.9532 - val_loss: 0.1430 - val_f1: 0.9643 - lr: 5.2335e-05\n","Epoch 363/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1351 - f1: 0.9507\n","Epoch 363: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1351 - f1: 0.9507 - val_loss: 0.1420 - val_f1: 0.9641 - lr: 5.2335e-05\n","Epoch 364/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1351 - f1: 0.9529\n","Epoch 364: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1351 - f1: 0.9529 - val_loss: 0.1518 - val_f1: 0.9644 - lr: 5.2335e-05\n","Epoch 365/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1378 - f1: 0.9547\n","Epoch 365: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1378 - f1: 0.9547 - val_loss: 0.1526 - val_f1: 0.9648 - lr: 5.2335e-05\n","Epoch 366/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1328 - f1: 0.9563\n","Epoch 366: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1328 - f1: 0.9563 - val_loss: 0.1496 - val_f1: 0.9641 - lr: 5.2335e-05\n","Epoch 367/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1376 - f1: 0.9484\n","Epoch 367: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1376 - f1: 0.9484 - val_loss: 0.1419 - val_f1: 0.9641 - lr: 5.2335e-05\n","Epoch 368/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1389 - f1: 0.9372\n","Epoch 368: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1389 - f1: 0.9372 - val_loss: 0.1344 - val_f1: 0.9642 - lr: 5.2335e-05\n","Epoch 369/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1306 - f1: 0.9521\n","Epoch 369: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1306 - f1: 0.9521 - val_loss: 0.1385 - val_f1: 0.9643 - lr: 5.2335e-05\n","Epoch 370/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1387 - f1: 0.9264\n","Epoch 370: val_f1 did not improve from 0.98579\n","\n","Epoch 370: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1387 - f1: 0.9264 - val_loss: 0.1394 - val_f1: 0.9640 - lr: 5.2335e-05\n","Epoch 371/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1311 - f1: 0.9500\n","Epoch 371: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1311 - f1: 0.9500 - val_loss: 0.1375 - val_f1: 0.9642 - lr: 4.7101e-05\n","Epoch 372/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1426 - f1: 0.9433\n","Epoch 372: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1426 - f1: 0.9433 - val_loss: 0.1399 - val_f1: 0.9642 - lr: 4.7101e-05\n","Epoch 373/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1383 - f1: 0.9541\n","Epoch 373: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1383 - f1: 0.9541 - val_loss: 0.1574 - val_f1: 0.9620 - lr: 4.7101e-05\n","Epoch 374/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1351 - f1: 0.9460\n","Epoch 374: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1351 - f1: 0.9460 - val_loss: 0.1340 - val_f1: 0.9650 - lr: 4.7101e-05\n","Epoch 375/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1359 - f1: 0.9443\n","Epoch 375: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1359 - f1: 0.9443 - val_loss: 0.1331 - val_f1: 0.9650 - lr: 4.7101e-05\n","Epoch 376/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1394 - f1: 0.9427\n","Epoch 376: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1394 - f1: 0.9427 - val_loss: 0.1566 - val_f1: 0.9610 - lr: 4.7101e-05\n","Epoch 377/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1351 - f1: 0.9480\n","Epoch 377: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1351 - f1: 0.9480 - val_loss: 0.1404 - val_f1: 0.9652 - lr: 4.7101e-05\n","Epoch 378/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1343 - f1: 0.9475\n","Epoch 378: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 246ms/step - loss: 0.1343 - f1: 0.9475 - val_loss: 0.1410 - val_f1: 0.9650 - lr: 4.7101e-05\n","Epoch 379/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1385 - f1: 0.9437\n","Epoch 379: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 3s 252ms/step - loss: 0.1385 - f1: 0.9437 - val_loss: 0.1438 - val_f1: 0.9648 - lr: 4.7101e-05\n","Epoch 380/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1394 - f1: 0.9191\n","Epoch 380: val_f1 did not improve from 0.98579\n","\n","Epoch 380: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1394 - f1: 0.9191 - val_loss: 0.1449 - val_f1: 0.9648 - lr: 4.7101e-05\n","Epoch 381/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1387 - f1: 0.9527\n","Epoch 381: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1387 - f1: 0.9527 - val_loss: 0.1740 - val_f1: 0.9619 - lr: 4.2391e-05\n","Epoch 382/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1392 - f1: 0.9508\n","Epoch 382: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1392 - f1: 0.9508 - val_loss: 0.1456 - val_f1: 0.9642 - lr: 4.2391e-05\n","Epoch 383/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1385 - f1: 0.9187\n","Epoch 383: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1385 - f1: 0.9187 - val_loss: 0.1323 - val_f1: 0.9647 - lr: 4.2391e-05\n","Epoch 384/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1405 - f1: 0.9514\n","Epoch 384: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1405 - f1: 0.9514 - val_loss: 0.1362 - val_f1: 0.9637 - lr: 4.2391e-05\n","Epoch 385/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1389 - f1: 0.9524\n","Epoch 385: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1389 - f1: 0.9524 - val_loss: 0.1427 - val_f1: 0.9626 - lr: 4.2391e-05\n","Epoch 386/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1330 - f1: 0.9556\n","Epoch 386: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1330 - f1: 0.9556 - val_loss: 0.1473 - val_f1: 0.9598 - lr: 4.2391e-05\n","Epoch 387/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1341 - f1: 0.9542\n","Epoch 387: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1341 - f1: 0.9542 - val_loss: 0.1511 - val_f1: 0.9594 - lr: 4.2391e-05\n","Epoch 388/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1337 - f1: 0.9515\n","Epoch 388: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1337 - f1: 0.9515 - val_loss: 0.1472 - val_f1: 0.9595 - lr: 4.2391e-05\n","Epoch 389/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1391 - f1: 0.9185\n","Epoch 389: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1391 - f1: 0.9185 - val_loss: 0.1500 - val_f1: 0.9615 - lr: 4.2391e-05\n","Epoch 390/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1346 - f1: 0.9415\n","Epoch 390: val_f1 did not improve from 0.98579\n","\n","Epoch 390: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1346 - f1: 0.9415 - val_loss: 0.1657 - val_f1: 0.9606 - lr: 4.2391e-05\n","Epoch 391/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1367 - f1: 0.9400\n","Epoch 391: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1367 - f1: 0.9400 - val_loss: 0.1389 - val_f1: 0.9649 - lr: 3.8152e-05\n","Epoch 392/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1338 - f1: 0.9377\n","Epoch 392: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1338 - f1: 0.9377 - val_loss: 0.1558 - val_f1: 0.9633 - lr: 3.8152e-05\n","Epoch 393/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1419 - f1: 0.9409\n","Epoch 393: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1419 - f1: 0.9409 - val_loss: 0.1367 - val_f1: 0.9667 - lr: 3.8152e-05\n","Epoch 394/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1280 - f1: 0.9575\n","Epoch 394: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1280 - f1: 0.9575 - val_loss: 0.1349 - val_f1: 0.9667 - lr: 3.8152e-05\n","Epoch 395/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1304 - f1: 0.9564\n","Epoch 395: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1304 - f1: 0.9564 - val_loss: 0.1416 - val_f1: 0.9662 - lr: 3.8152e-05\n","Epoch 396/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1289 - f1: 0.9428\n","Epoch 396: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1289 - f1: 0.9428 - val_loss: 0.1427 - val_f1: 0.9638 - lr: 3.8152e-05\n","Epoch 397/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1254 - f1: 0.9569\n","Epoch 397: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1254 - f1: 0.9569 - val_loss: 0.1461 - val_f1: 0.9641 - lr: 3.8152e-05\n","Epoch 398/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1279 - f1: 0.9553\n","Epoch 398: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1279 - f1: 0.9553 - val_loss: 0.1502 - val_f1: 0.9637 - lr: 3.8152e-05\n","Epoch 399/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1266 - f1: 0.9267\n","Epoch 399: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1266 - f1: 0.9267 - val_loss: 0.1486 - val_f1: 0.9641 - lr: 3.8152e-05\n","Epoch 400/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1272 - f1: 0.9588\n","Epoch 400: val_f1 did not improve from 0.98579\n","\n","Epoch 400: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1272 - f1: 0.9588 - val_loss: 0.1549 - val_f1: 0.9645 - lr: 3.8152e-05\n","Epoch 401/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1294 - f1: 0.9568\n","Epoch 401: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1294 - f1: 0.9568 - val_loss: 0.1596 - val_f1: 0.9646 - lr: 3.4337e-05\n","Epoch 402/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1304 - f1: 0.9452\n","Epoch 402: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1304 - f1: 0.9452 - val_loss: 0.1627 - val_f1: 0.9638 - lr: 3.4337e-05\n","Epoch 403/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1282 - f1: 0.9580\n","Epoch 403: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1282 - f1: 0.9580 - val_loss: 0.1567 - val_f1: 0.9639 - lr: 3.4337e-05\n","Epoch 404/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1228 - f1: 0.9293\n","Epoch 404: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1228 - f1: 0.9293 - val_loss: 0.1540 - val_f1: 0.9642 - lr: 3.4337e-05\n","Epoch 405/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1258 - f1: 0.9558\n","Epoch 405: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 236ms/step - loss: 0.1258 - f1: 0.9558 - val_loss: 0.1436 - val_f1: 0.9640 - lr: 3.4337e-05\n","Epoch 406/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1333 - f1: 0.9514\n","Epoch 406: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1333 - f1: 0.9514 - val_loss: 0.1430 - val_f1: 0.9641 - lr: 3.4337e-05\n","Epoch 407/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1272 - f1: 0.9546\n","Epoch 407: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1272 - f1: 0.9546 - val_loss: 0.1428 - val_f1: 0.9639 - lr: 3.4337e-05\n","Epoch 408/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1421 - f1: 0.9436\n","Epoch 408: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1421 - f1: 0.9436 - val_loss: 0.1624 - val_f1: 0.9607 - lr: 3.4337e-05\n","Epoch 409/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1521 - f1: 0.9490\n","Epoch 409: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1521 - f1: 0.9490 - val_loss: 0.1854 - val_f1: 0.9565 - lr: 3.4337e-05\n","Epoch 410/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1531 - f1: 0.9475\n","Epoch 410: val_f1 did not improve from 0.98579\n","\n","Epoch 410: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1531 - f1: 0.9475 - val_loss: 0.1606 - val_f1: 0.9603 - lr: 3.4337e-05\n","Epoch 411/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1432 - f1: 0.9407\n","Epoch 411: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1432 - f1: 0.9407 - val_loss: 0.1503 - val_f1: 0.9624 - lr: 3.0903e-05\n","Epoch 412/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1401 - f1: 0.9524\n","Epoch 412: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1401 - f1: 0.9524 - val_loss: 0.1628 - val_f1: 0.9593 - lr: 3.0903e-05\n","Epoch 413/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1385 - f1: 0.9455\n","Epoch 413: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 250ms/step - loss: 0.1385 - f1: 0.9455 - val_loss: 0.1469 - val_f1: 0.9637 - lr: 3.0903e-05\n","Epoch 414/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1358 - f1: 0.9488\n","Epoch 414: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1358 - f1: 0.9488 - val_loss: 0.1540 - val_f1: 0.9637 - lr: 3.0903e-05\n","Epoch 415/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1367 - f1: 0.9530\n","Epoch 415: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1367 - f1: 0.9530 - val_loss: 0.1557 - val_f1: 0.9641 - lr: 3.0903e-05\n","Epoch 416/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1319 - f1: 0.9559\n","Epoch 416: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1319 - f1: 0.9559 - val_loss: 0.1599 - val_f1: 0.9639 - lr: 3.0903e-05\n","Epoch 417/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1281 - f1: 0.9542\n","Epoch 417: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1281 - f1: 0.9542 - val_loss: 0.1584 - val_f1: 0.9638 - lr: 3.0903e-05\n","Epoch 418/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1260 - f1: 0.9274\n","Epoch 418: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1260 - f1: 0.9274 - val_loss: 0.1537 - val_f1: 0.9637 - lr: 3.0903e-05\n","Epoch 419/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1330 - f1: 0.9559\n","Epoch 419: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1330 - f1: 0.9559 - val_loss: 0.1602 - val_f1: 0.9642 - lr: 3.0903e-05\n","Epoch 420/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1282 - f1: 0.9582\n","Epoch 420: val_f1 did not improve from 0.98579\n","\n","Epoch 420: ReduceLROnPlateau reducing learning rate to 2.7812844200525434e-05.\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1282 - f1: 0.9582 - val_loss: 0.1539 - val_f1: 0.9641 - lr: 3.0903e-05\n","Epoch 421/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1289 - f1: 0.9601\n","Epoch 421: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1289 - f1: 0.9601 - val_loss: 0.1506 - val_f1: 0.9639 - lr: 2.7813e-05\n","Epoch 422/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1300 - f1: 0.9595\n","Epoch 422: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1300 - f1: 0.9595 - val_loss: 0.1524 - val_f1: 0.9641 - lr: 2.7813e-05\n","Epoch 423/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1306 - f1: 0.9468\n","Epoch 423: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1306 - f1: 0.9468 - val_loss: 0.1530 - val_f1: 0.9639 - lr: 2.7813e-05\n","Epoch 424/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1256 - f1: 0.9555\n","Epoch 424: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1256 - f1: 0.9555 - val_loss: 0.1461 - val_f1: 0.9642 - lr: 2.7813e-05\n","Epoch 425/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1256 - f1: 0.9554\n","Epoch 425: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1256 - f1: 0.9554 - val_loss: 0.1452 - val_f1: 0.9638 - lr: 2.7813e-05\n","Epoch 426/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1256 - f1: 0.9590\n","Epoch 426: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1256 - f1: 0.9590 - val_loss: 0.1491 - val_f1: 0.9636 - lr: 2.7813e-05\n","Epoch 427/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1245 - f1: 0.9554\n","Epoch 427: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1245 - f1: 0.9554 - val_loss: 0.1514 - val_f1: 0.9634 - lr: 2.7813e-05\n","Epoch 428/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1318 - f1: 0.9228\n","Epoch 428: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1318 - f1: 0.9228 - val_loss: 0.1467 - val_f1: 0.9635 - lr: 2.7813e-05\n","Epoch 429/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1513 - f1: 0.9513\n","Epoch 429: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1513 - f1: 0.9513 - val_loss: 0.1575 - val_f1: 0.9635 - lr: 2.7813e-05\n","Epoch 430/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1329 - f1: 0.9334\n","Epoch 430: val_f1 did not improve from 0.98579\n","\n","Epoch 430: ReduceLROnPlateau reducing learning rate to 2.5031560107890984e-05.\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1329 - f1: 0.9334 - val_loss: 0.1494 - val_f1: 0.9642 - lr: 2.7813e-05\n","Epoch 431/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1349 - f1: 0.9534\n","Epoch 431: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1349 - f1: 0.9534 - val_loss: 0.1004 - val_f1: 0.9847 - lr: 2.5032e-05\n","Epoch 432/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1361 - f1: 0.9578\n","Epoch 432: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1361 - f1: 0.9578 - val_loss: 0.1051 - val_f1: 0.9803 - lr: 2.5032e-05\n","Epoch 433/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1333 - f1: 0.9591\n","Epoch 433: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1333 - f1: 0.9591 - val_loss: 0.1019 - val_f1: 0.9803 - lr: 2.5032e-05\n","Epoch 434/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1325 - f1: 0.9488\n","Epoch 434: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1325 - f1: 0.9488 - val_loss: 0.1091 - val_f1: 0.9717 - lr: 2.5032e-05\n","Epoch 435/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1338 - f1: 0.9584\n","Epoch 435: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1338 - f1: 0.9584 - val_loss: 0.1236 - val_f1: 0.9655 - lr: 2.5032e-05\n","Epoch 436/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1293 - f1: 0.9242\n","Epoch 436: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1293 - f1: 0.9242 - val_loss: 0.1152 - val_f1: 0.9685 - lr: 2.5032e-05\n","Epoch 437/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1466 - f1: 0.9534\n","Epoch 437: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1466 - f1: 0.9534 - val_loss: 0.1235 - val_f1: 0.9668 - lr: 2.5032e-05\n","Epoch 438/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1466 - f1: 0.9551\n","Epoch 438: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1466 - f1: 0.9551 - val_loss: 0.1446 - val_f1: 0.9624 - lr: 2.5032e-05\n","Epoch 439/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1293 - f1: 0.9560\n","Epoch 439: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1293 - f1: 0.9560 - val_loss: 0.1480 - val_f1: 0.9635 - lr: 2.5032e-05\n","Epoch 440/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1261 - f1: 0.9570\n","Epoch 440: val_f1 did not improve from 0.98579\n","\n","Epoch 440: ReduceLROnPlateau reducing learning rate to 2.2528404588229024e-05.\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1261 - f1: 0.9570 - val_loss: 0.1525 - val_f1: 0.9642 - lr: 2.5032e-05\n","Epoch 441/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1300 - f1: 0.9481\n","Epoch 441: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1300 - f1: 0.9481 - val_loss: 0.1493 - val_f1: 0.9642 - lr: 2.2528e-05\n","Epoch 442/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1226 - f1: 0.9590\n","Epoch 442: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1226 - f1: 0.9590 - val_loss: 0.1381 - val_f1: 0.9646 - lr: 2.2528e-05\n","Epoch 443/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1243 - f1: 0.9626\n","Epoch 443: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1243 - f1: 0.9626 - val_loss: 0.1360 - val_f1: 0.9648 - lr: 2.2528e-05\n","Epoch 444/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1284 - f1: 0.9498\n","Epoch 444: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1284 - f1: 0.9498 - val_loss: 0.1415 - val_f1: 0.9642 - lr: 2.2528e-05\n","Epoch 445/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1266 - f1: 0.9581\n","Epoch 445: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1266 - f1: 0.9581 - val_loss: 0.1463 - val_f1: 0.9644 - lr: 2.2528e-05\n","Epoch 446/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1179 - f1: 0.9635\n","Epoch 446: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1179 - f1: 0.9635 - val_loss: 0.1405 - val_f1: 0.9647 - lr: 2.2528e-05\n","Epoch 447/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1203 - f1: 0.9499\n","Epoch 447: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1203 - f1: 0.9499 - val_loss: 0.1452 - val_f1: 0.9643 - lr: 2.2528e-05\n","Epoch 448/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1412 - f1: 0.9542\n","Epoch 448: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1412 - f1: 0.9542 - val_loss: 0.1819 - val_f1: 0.9602 - lr: 2.2528e-05\n","Epoch 449/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1543 - f1: 0.9370\n","Epoch 449: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1543 - f1: 0.9370 - val_loss: 0.1522 - val_f1: 0.9611 - lr: 2.2528e-05\n","Epoch 450/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1242 - f1: 0.9579\n","Epoch 450: val_f1 did not improve from 0.98579\n","\n","Epoch 450: ReduceLROnPlateau reducing learning rate to 2.0275563474569936e-05.\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1242 - f1: 0.9579 - val_loss: 0.1390 - val_f1: 0.9644 - lr: 2.2528e-05\n","Epoch 451/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1264 - f1: 0.9607\n","Epoch 451: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1264 - f1: 0.9607 - val_loss: 0.1400 - val_f1: 0.9645 - lr: 2.0276e-05\n","Epoch 452/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1195 - f1: 0.9635\n","Epoch 452: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1195 - f1: 0.9635 - val_loss: 0.1415 - val_f1: 0.9643 - lr: 2.0276e-05\n","Epoch 453/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1252 - f1: 0.9634\n","Epoch 453: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1252 - f1: 0.9634 - val_loss: 0.1417 - val_f1: 0.9644 - lr: 2.0276e-05\n","Epoch 454/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1225 - f1: 0.9533\n","Epoch 454: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 3s 277ms/step - loss: 0.1225 - f1: 0.9533 - val_loss: 0.1372 - val_f1: 0.9648 - lr: 2.0276e-05\n","Epoch 455/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1277 - f1: 0.9543\n","Epoch 455: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 248ms/step - loss: 0.1277 - f1: 0.9543 - val_loss: 0.1299 - val_f1: 0.9649 - lr: 2.0276e-05\n","Epoch 456/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1225 - f1: 0.9597\n","Epoch 456: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1225 - f1: 0.9597 - val_loss: 0.1571 - val_f1: 0.9610 - lr: 2.0276e-05\n","Epoch 457/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1286 - f1: 0.9493\n","Epoch 457: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 3s 249ms/step - loss: 0.1286 - f1: 0.9493 - val_loss: 0.1508 - val_f1: 0.9632 - lr: 2.0276e-05\n","Epoch 458/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1230 - f1: 0.9547\n","Epoch 458: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 3s 250ms/step - loss: 0.1230 - f1: 0.9547 - val_loss: 0.1382 - val_f1: 0.9642 - lr: 2.0276e-05\n","Epoch 459/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1251 - f1: 0.9612\n","Epoch 459: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 3s 264ms/step - loss: 0.1251 - f1: 0.9612 - val_loss: 0.1408 - val_f1: 0.9639 - lr: 2.0276e-05\n","Epoch 460/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1238 - f1: 0.9594\n","Epoch 460: val_f1 did not improve from 0.98579\n","\n","Epoch 460: ReduceLROnPlateau reducing learning rate to 1.8248007290821987e-05.\n","10/10 [==============================] - 3s 253ms/step - loss: 0.1238 - f1: 0.9594 - val_loss: 0.1413 - val_f1: 0.9638 - lr: 2.0276e-05\n","Epoch 461/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1180 - f1: 0.9608\n","Epoch 461: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 235ms/step - loss: 0.1180 - f1: 0.9608 - val_loss: 0.1416 - val_f1: 0.9639 - lr: 1.8248e-05\n","Epoch 462/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1162 - f1: 0.9619\n","Epoch 462: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1162 - f1: 0.9619 - val_loss: 0.1378 - val_f1: 0.9642 - lr: 1.8248e-05\n","Epoch 463/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1207 - f1: 0.9619\n","Epoch 463: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1207 - f1: 0.9619 - val_loss: 0.1329 - val_f1: 0.9643 - lr: 1.8248e-05\n","Epoch 464/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1162 - f1: 0.9624\n","Epoch 464: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1162 - f1: 0.9624 - val_loss: 0.1366 - val_f1: 0.9642 - lr: 1.8248e-05\n","Epoch 465/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1197 - f1: 0.9575\n","Epoch 465: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 236ms/step - loss: 0.1197 - f1: 0.9575 - val_loss: 0.1381 - val_f1: 0.9641 - lr: 1.8248e-05\n","Epoch 466/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1188 - f1: 0.9586\n","Epoch 466: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1188 - f1: 0.9586 - val_loss: 0.1457 - val_f1: 0.9642 - lr: 1.8248e-05\n","Epoch 467/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1191 - f1: 0.9580\n","Epoch 467: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1191 - f1: 0.9580 - val_loss: 0.1466 - val_f1: 0.9641 - lr: 1.8248e-05\n","Epoch 468/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1197 - f1: 0.9626\n","Epoch 468: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1197 - f1: 0.9626 - val_loss: 0.1473 - val_f1: 0.9644 - lr: 1.8248e-05\n","Epoch 469/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1249 - f1: 0.9525\n","Epoch 469: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 235ms/step - loss: 0.1249 - f1: 0.9525 - val_loss: 0.1505 - val_f1: 0.9642 - lr: 1.8248e-05\n","Epoch 470/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1175 - f1: 0.9624\n","Epoch 470: val_f1 did not improve from 0.98579\n","\n","Epoch 470: ReduceLROnPlateau reducing learning rate to 1.6423206398030745e-05.\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1175 - f1: 0.9624 - val_loss: 0.1431 - val_f1: 0.9646 - lr: 1.8248e-05\n","Epoch 471/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1199 - f1: 0.9637\n","Epoch 471: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 236ms/step - loss: 0.1199 - f1: 0.9637 - val_loss: 0.1456 - val_f1: 0.9646 - lr: 1.6423e-05\n","Epoch 472/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1188 - f1: 0.9319\n","Epoch 472: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 236ms/step - loss: 0.1188 - f1: 0.9319 - val_loss: 0.1489 - val_f1: 0.9643 - lr: 1.6423e-05\n","Epoch 473/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1171 - f1: 0.9616\n","Epoch 473: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1171 - f1: 0.9616 - val_loss: 0.1651 - val_f1: 0.9640 - lr: 1.6423e-05\n","Epoch 474/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1194 - f1: 0.9608\n","Epoch 474: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 235ms/step - loss: 0.1194 - f1: 0.9608 - val_loss: 0.1594 - val_f1: 0.9639 - lr: 1.6423e-05\n","Epoch 475/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1166 - f1: 0.9623\n","Epoch 475: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1166 - f1: 0.9623 - val_loss: 0.1501 - val_f1: 0.9639 - lr: 1.6423e-05\n","Epoch 476/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1177 - f1: 0.9624\n","Epoch 476: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1177 - f1: 0.9624 - val_loss: 0.1511 - val_f1: 0.9639 - lr: 1.6423e-05\n","Epoch 477/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1251 - f1: 0.9642\n","Epoch 477: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1251 - f1: 0.9642 - val_loss: 0.1497 - val_f1: 0.9639 - lr: 1.6423e-05\n","Epoch 478/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1226 - f1: 0.9633\n","Epoch 478: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1226 - f1: 0.9633 - val_loss: 0.1419 - val_f1: 0.9642 - lr: 1.6423e-05\n","Epoch 479/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1214 - f1: 0.9371\n","Epoch 479: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1214 - f1: 0.9371 - val_loss: 0.1341 - val_f1: 0.9650 - lr: 1.6423e-05\n","Epoch 480/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1236 - f1: 0.9599\n","Epoch 480: val_f1 did not improve from 0.98579\n","\n","Epoch 480: ReduceLROnPlateau reducing learning rate to 1.4780885430809576e-05.\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1236 - f1: 0.9599 - val_loss: 0.1092 - val_f1: 0.9717 - lr: 1.6423e-05\n","Epoch 481/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1169 - f1: 0.9531\n","Epoch 481: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 3s 251ms/step - loss: 0.1169 - f1: 0.9531 - val_loss: 0.1113 - val_f1: 0.9696 - lr: 1.4781e-05\n","Epoch 482/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1192 - f1: 0.9630\n","Epoch 482: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1192 - f1: 0.9630 - val_loss: 0.1237 - val_f1: 0.9664 - lr: 1.4781e-05\n","Epoch 483/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1204 - f1: 0.9638\n","Epoch 483: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1204 - f1: 0.9638 - val_loss: 0.1285 - val_f1: 0.9656 - lr: 1.4781e-05\n","Epoch 484/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1248 - f1: 0.9603\n","Epoch 484: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1248 - f1: 0.9603 - val_loss: 0.1350 - val_f1: 0.9649 - lr: 1.4781e-05\n","Epoch 485/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1150 - f1: 0.9459\n","Epoch 485: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1150 - f1: 0.9459 - val_loss: 0.1388 - val_f1: 0.9646 - lr: 1.4781e-05\n","Epoch 486/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1184 - f1: 0.9551\n","Epoch 486: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1184 - f1: 0.9551 - val_loss: 0.1425 - val_f1: 0.9644 - lr: 1.4781e-05\n","Epoch 487/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1197 - f1: 0.9635\n","Epoch 487: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1197 - f1: 0.9635 - val_loss: 0.1451 - val_f1: 0.9643 - lr: 1.4781e-05\n","Epoch 488/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1192 - f1: 0.9625\n","Epoch 488: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1192 - f1: 0.9625 - val_loss: 0.1465 - val_f1: 0.9643 - lr: 1.4781e-05\n","Epoch 489/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1213 - f1: 0.9533\n","Epoch 489: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1213 - f1: 0.9533 - val_loss: 0.1490 - val_f1: 0.9643 - lr: 1.4781e-05\n","Epoch 490/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1175 - f1: 0.9458\n","Epoch 490: val_f1 did not improve from 0.98579\n","\n","Epoch 490: ReduceLROnPlateau reducing learning rate to 1.3302796560310526e-05.\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1175 - f1: 0.9458 - val_loss: 0.1449 - val_f1: 0.9642 - lr: 1.4781e-05\n","Epoch 491/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1174 - f1: 0.9548\n","Epoch 491: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1174 - f1: 0.9548 - val_loss: 0.1536 - val_f1: 0.9642 - lr: 1.3303e-05\n","Epoch 492/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1188 - f1: 0.9625\n","Epoch 492: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1188 - f1: 0.9625 - val_loss: 0.1530 - val_f1: 0.9642 - lr: 1.3303e-05\n","Epoch 493/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1214 - f1: 0.9612\n","Epoch 493: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1214 - f1: 0.9612 - val_loss: 0.1487 - val_f1: 0.9640 - lr: 1.3303e-05\n","Epoch 494/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1182 - f1: 0.9603\n","Epoch 494: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1182 - f1: 0.9603 - val_loss: 0.1488 - val_f1: 0.9640 - lr: 1.3303e-05\n","Epoch 495/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1194 - f1: 0.9627\n","Epoch 495: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1194 - f1: 0.9627 - val_loss: 0.1454 - val_f1: 0.9642 - lr: 1.3303e-05\n","Epoch 496/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1190 - f1: 0.9639\n","Epoch 496: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1190 - f1: 0.9639 - val_loss: 0.1466 - val_f1: 0.9642 - lr: 1.3303e-05\n","Epoch 497/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1163 - f1: 0.9619\n","Epoch 497: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1163 - f1: 0.9619 - val_loss: 0.1481 - val_f1: 0.9641 - lr: 1.3303e-05\n","Epoch 498/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1165 - f1: 0.9625\n","Epoch 498: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1165 - f1: 0.9625 - val_loss: 0.1505 - val_f1: 0.9640 - lr: 1.3303e-05\n","Epoch 499/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1130 - f1: 0.9647\n","Epoch 499: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1130 - f1: 0.9647 - val_loss: 0.1466 - val_f1: 0.9642 - lr: 1.3303e-05\n","Epoch 500/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1157 - f1: 0.9625\n","Epoch 500: val_f1 did not improve from 0.98579\n","\n","Epoch 500: ReduceLROnPlateau reducing learning rate to 1.1972517313552089e-05.\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1157 - f1: 0.9625 - val_loss: 0.1495 - val_f1: 0.9641 - lr: 1.3303e-05\n","Epoch 501/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1188 - f1: 0.9631\n","Epoch 501: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1188 - f1: 0.9631 - val_loss: 0.1488 - val_f1: 0.9641 - lr: 1.1973e-05\n","Epoch 502/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1130 - f1: 0.9427\n","Epoch 502: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1130 - f1: 0.9427 - val_loss: 0.1480 - val_f1: 0.9642 - lr: 1.1973e-05\n","Epoch 503/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1123 - f1: 0.9261\n","Epoch 503: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1123 - f1: 0.9261 - val_loss: 0.1456 - val_f1: 0.9642 - lr: 1.1973e-05\n","Epoch 504/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1183 - f1: 0.9369\n","Epoch 504: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1183 - f1: 0.9369 - val_loss: 0.1557 - val_f1: 0.9639 - lr: 1.1973e-05\n","Epoch 505/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1176 - f1: 0.9493\n","Epoch 505: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 245ms/step - loss: 0.1176 - f1: 0.9493 - val_loss: 0.1577 - val_f1: 0.9639 - lr: 1.1973e-05\n","Epoch 506/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1208 - f1: 0.9606\n","Epoch 506: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1208 - f1: 0.9606 - val_loss: 0.1628 - val_f1: 0.9639 - lr: 1.1973e-05\n","Epoch 507/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1247 - f1: 0.9625\n","Epoch 507: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1247 - f1: 0.9625 - val_loss: 0.1503 - val_f1: 0.9639 - lr: 1.1973e-05\n","Epoch 508/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1179 - f1: 0.9628\n","Epoch 508: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1179 - f1: 0.9628 - val_loss: 0.1430 - val_f1: 0.9642 - lr: 1.1973e-05\n","Epoch 509/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1159 - f1: 0.9652\n","Epoch 509: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1159 - f1: 0.9652 - val_loss: 0.1411 - val_f1: 0.9642 - lr: 1.1973e-05\n","Epoch 510/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1154 - f1: 0.9553\n","Epoch 510: val_f1 did not improve from 0.98579\n","\n","Epoch 510: ReduceLROnPlateau reducing learning rate to 1.077526558219688e-05.\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1154 - f1: 0.9553 - val_loss: 0.1436 - val_f1: 0.9641 - lr: 1.1973e-05\n","Epoch 511/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1180 - f1: 0.9589\n","Epoch 511: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1180 - f1: 0.9589 - val_loss: 0.1429 - val_f1: 0.9641 - lr: 1.0775e-05\n","Epoch 512/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1236 - f1: 0.9530\n","Epoch 512: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1236 - f1: 0.9530 - val_loss: 0.1428 - val_f1: 0.9641 - lr: 1.0775e-05\n","Epoch 513/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1240 - f1: 0.9534\n","Epoch 513: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1240 - f1: 0.9534 - val_loss: 0.1519 - val_f1: 0.9642 - lr: 1.0775e-05\n","Epoch 514/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1177 - f1: 0.9624\n","Epoch 514: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1177 - f1: 0.9624 - val_loss: 0.1530 - val_f1: 0.9639 - lr: 1.0775e-05\n","Epoch 515/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1189 - f1: 0.9260\n","Epoch 515: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1189 - f1: 0.9260 - val_loss: 0.1538 - val_f1: 0.9638 - lr: 1.0775e-05\n","Epoch 516/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1248 - f1: 0.9333\n","Epoch 516: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1248 - f1: 0.9333 - val_loss: 0.1578 - val_f1: 0.9639 - lr: 1.0775e-05\n","Epoch 517/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1227 - f1: 0.9607\n","Epoch 517: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1227 - f1: 0.9607 - val_loss: 0.1567 - val_f1: 0.9642 - lr: 1.0775e-05\n","Epoch 518/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1198 - f1: 0.9594\n","Epoch 518: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1198 - f1: 0.9594 - val_loss: 0.1514 - val_f1: 0.9643 - lr: 1.0775e-05\n","Epoch 519/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1153 - f1: 0.9639\n","Epoch 519: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1153 - f1: 0.9639 - val_loss: 0.1434 - val_f1: 0.9643 - lr: 1.0775e-05\n","Epoch 520/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1196 - f1: 0.9617\n","Epoch 520: val_f1 did not improve from 0.98579\n","\n","Epoch 520: ReduceLROnPlateau reducing learning rate to 9.697739187686238e-06.\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1196 - f1: 0.9617 - val_loss: 0.1423 - val_f1: 0.9643 - lr: 1.0775e-05\n","Epoch 521/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1213 - f1: 0.9363\n","Epoch 521: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1213 - f1: 0.9363 - val_loss: 0.1434 - val_f1: 0.9643 - lr: 9.6977e-06\n","Epoch 522/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1182 - f1: 0.9658\n","Epoch 522: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1182 - f1: 0.9658 - val_loss: 0.1493 - val_f1: 0.9642 - lr: 9.6977e-06\n","Epoch 523/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1186 - f1: 0.9651\n","Epoch 523: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1186 - f1: 0.9651 - val_loss: 0.1482 - val_f1: 0.9642 - lr: 9.6977e-06\n","Epoch 524/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1190 - f1: 0.9613\n","Epoch 524: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1190 - f1: 0.9613 - val_loss: 0.1459 - val_f1: 0.9643 - lr: 9.6977e-06\n","Epoch 525/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1256 - f1: 0.9475\n","Epoch 525: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1256 - f1: 0.9475 - val_loss: 0.1489 - val_f1: 0.9642 - lr: 9.6977e-06\n","Epoch 526/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1150 - f1: 0.9626\n","Epoch 526: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1150 - f1: 0.9626 - val_loss: 0.1604 - val_f1: 0.9639 - lr: 9.6977e-06\n","Epoch 527/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1160 - f1: 0.9609\n","Epoch 527: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1160 - f1: 0.9609 - val_loss: 0.1625 - val_f1: 0.9639 - lr: 9.6977e-06\n","Epoch 528/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1179 - f1: 0.9563\n","Epoch 528: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1179 - f1: 0.9563 - val_loss: 0.1582 - val_f1: 0.9639 - lr: 9.6977e-06\n","Epoch 529/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1195 - f1: 0.9597\n","Epoch 529: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 3s 255ms/step - loss: 0.1195 - f1: 0.9597 - val_loss: 0.1512 - val_f1: 0.9641 - lr: 9.6977e-06\n","Epoch 530/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1105 - f1: 0.9650\n","Epoch 530: val_f1 did not improve from 0.98579\n","\n","Epoch 530: ReduceLROnPlateau reducing learning rate to 8.727965268917615e-06.\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1105 - f1: 0.9650 - val_loss: 0.1488 - val_f1: 0.9642 - lr: 9.6977e-06\n","Epoch 531/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1130 - f1: 0.9650\n","Epoch 531: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1130 - f1: 0.9650 - val_loss: 0.1485 - val_f1: 0.9642 - lr: 8.7280e-06\n","Epoch 532/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1199 - f1: 0.9591\n","Epoch 532: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1199 - f1: 0.9591 - val_loss: 0.1492 - val_f1: 0.9640 - lr: 8.7280e-06\n","Epoch 533/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1154 - f1: 0.9516\n","Epoch 533: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1154 - f1: 0.9516 - val_loss: 0.1493 - val_f1: 0.9642 - lr: 8.7280e-06\n","Epoch 534/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1164 - f1: 0.9633\n","Epoch 534: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1164 - f1: 0.9633 - val_loss: 0.1505 - val_f1: 0.9643 - lr: 8.7280e-06\n","Epoch 535/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1194 - f1: 0.9633\n","Epoch 535: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1194 - f1: 0.9633 - val_loss: 0.1525 - val_f1: 0.9643 - lr: 8.7280e-06\n","Epoch 536/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1146 - f1: 0.9654\n","Epoch 536: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1146 - f1: 0.9654 - val_loss: 0.1551 - val_f1: 0.9642 - lr: 8.7280e-06\n","Epoch 537/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1149 - f1: 0.9635\n","Epoch 537: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1149 - f1: 0.9635 - val_loss: 0.1549 - val_f1: 0.9641 - lr: 8.7280e-06\n","Epoch 538/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1162 - f1: 0.9641\n","Epoch 538: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1162 - f1: 0.9641 - val_loss: 0.1573 - val_f1: 0.9640 - lr: 8.7280e-06\n","Epoch 539/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1109 - f1: 0.9652\n","Epoch 539: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1109 - f1: 0.9652 - val_loss: 0.1561 - val_f1: 0.9640 - lr: 8.7280e-06\n","Epoch 540/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1137 - f1: 0.9659\n","Epoch 540: val_f1 did not improve from 0.98579\n","\n","Epoch 540: ReduceLROnPlateau reducing learning rate to 7.855168496462283e-06.\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1137 - f1: 0.9659 - val_loss: 0.1524 - val_f1: 0.9639 - lr: 8.7280e-06\n","Epoch 541/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1231 - f1: 0.9039\n","Epoch 541: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1231 - f1: 0.9039 - val_loss: 0.1519 - val_f1: 0.9641 - lr: 7.8552e-06\n","Epoch 542/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1200 - f1: 0.9629\n","Epoch 542: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1200 - f1: 0.9629 - val_loss: 0.1547 - val_f1: 0.9640 - lr: 7.8552e-06\n","Epoch 543/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1132 - f1: 0.9627\n","Epoch 543: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1132 - f1: 0.9627 - val_loss: 0.1577 - val_f1: 0.9638 - lr: 7.8552e-06\n","Epoch 544/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1163 - f1: 0.9616\n","Epoch 544: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1163 - f1: 0.9616 - val_loss: 0.1531 - val_f1: 0.9638 - lr: 7.8552e-06\n","Epoch 545/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1212 - f1: 0.9299\n","Epoch 545: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 249ms/step - loss: 0.1212 - f1: 0.9299 - val_loss: 0.1519 - val_f1: 0.9639 - lr: 7.8552e-06\n","Epoch 546/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1121 - f1: 0.9652\n","Epoch 546: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1121 - f1: 0.9652 - val_loss: 0.1491 - val_f1: 0.9639 - lr: 7.8552e-06\n","Epoch 547/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1165 - f1: 0.9601\n","Epoch 547: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1165 - f1: 0.9601 - val_loss: 0.1496 - val_f1: 0.9638 - lr: 7.8552e-06\n","Epoch 548/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1173 - f1: 0.9650\n","Epoch 548: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 245ms/step - loss: 0.1173 - f1: 0.9650 - val_loss: 0.1496 - val_f1: 0.9638 - lr: 7.8552e-06\n","Epoch 549/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1155 - f1: 0.9652\n","Epoch 549: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 3s 248ms/step - loss: 0.1155 - f1: 0.9652 - val_loss: 0.1480 - val_f1: 0.9640 - lr: 7.8552e-06\n","Epoch 550/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1145 - f1: 0.9554\n","Epoch 550: val_f1 did not improve from 0.98579\n","\n","Epoch 550: ReduceLROnPlateau reducing learning rate to 7.069651564961533e-06.\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1145 - f1: 0.9554 - val_loss: 0.1483 - val_f1: 0.9639 - lr: 7.8552e-06\n","Epoch 551/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1178 - f1: 0.9657\n","Epoch 551: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1178 - f1: 0.9657 - val_loss: 0.1520 - val_f1: 0.9638 - lr: 7.0697e-06\n","Epoch 552/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1149 - f1: 0.9646\n","Epoch 552: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1149 - f1: 0.9646 - val_loss: 0.1528 - val_f1: 0.9638 - lr: 7.0697e-06\n","Epoch 553/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1160 - f1: 0.9602\n","Epoch 553: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1160 - f1: 0.9602 - val_loss: 0.1531 - val_f1: 0.9638 - lr: 7.0697e-06\n","Epoch 554/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1122 - f1: 0.9355\n","Epoch 554: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1122 - f1: 0.9355 - val_loss: 0.1527 - val_f1: 0.9638 - lr: 7.0697e-06\n","Epoch 555/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1157 - f1: 0.9511\n","Epoch 555: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1157 - f1: 0.9511 - val_loss: 0.1479 - val_f1: 0.9638 - lr: 7.0697e-06\n","Epoch 556/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1124 - f1: 0.9641\n","Epoch 556: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1124 - f1: 0.9641 - val_loss: 0.1517 - val_f1: 0.9638 - lr: 7.0697e-06\n","Epoch 557/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1154 - f1: 0.9648\n","Epoch 557: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1154 - f1: 0.9648 - val_loss: 0.1550 - val_f1: 0.9636 - lr: 7.0697e-06\n","Epoch 558/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1170 - f1: 0.9585\n","Epoch 558: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 244ms/step - loss: 0.1170 - f1: 0.9585 - val_loss: 0.1539 - val_f1: 0.9636 - lr: 7.0697e-06\n","Epoch 559/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1133 - f1: 0.9663\n","Epoch 559: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1133 - f1: 0.9663 - val_loss: 0.1531 - val_f1: 0.9637 - lr: 7.0697e-06\n","Epoch 560/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1106 - f1: 0.9646\n","Epoch 560: val_f1 did not improve from 0.98579\n","\n","Epoch 560: ReduceLROnPlateau reducing learning rate to 6.362686326610856e-06.\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1106 - f1: 0.9646 - val_loss: 0.1516 - val_f1: 0.9638 - lr: 7.0697e-06\n","Epoch 561/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1173 - f1: 0.9641\n","Epoch 561: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1173 - f1: 0.9641 - val_loss: 0.1515 - val_f1: 0.9638 - lr: 6.3627e-06\n","Epoch 562/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1164 - f1: 0.9626\n","Epoch 562: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1164 - f1: 0.9626 - val_loss: 0.1537 - val_f1: 0.9636 - lr: 6.3627e-06\n","Epoch 563/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1169 - f1: 0.9632\n","Epoch 563: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1169 - f1: 0.9632 - val_loss: 0.1552 - val_f1: 0.9635 - lr: 6.3627e-06\n","Epoch 564/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1167 - f1: 0.9625\n","Epoch 564: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 245ms/step - loss: 0.1167 - f1: 0.9625 - val_loss: 0.1516 - val_f1: 0.9638 - lr: 6.3627e-06\n","Epoch 565/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1142 - f1: 0.9642\n","Epoch 565: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1142 - f1: 0.9642 - val_loss: 0.1501 - val_f1: 0.9638 - lr: 6.3627e-06\n","Epoch 566/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1194 - f1: 0.9504\n","Epoch 566: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1194 - f1: 0.9504 - val_loss: 0.1514 - val_f1: 0.9639 - lr: 6.3627e-06\n","Epoch 567/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1154 - f1: 0.9667\n","Epoch 567: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1154 - f1: 0.9667 - val_loss: 0.1506 - val_f1: 0.9641 - lr: 6.3627e-06\n","Epoch 568/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1152 - f1: 0.9643\n","Epoch 568: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1152 - f1: 0.9643 - val_loss: 0.1498 - val_f1: 0.9641 - lr: 6.3627e-06\n","Epoch 569/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1115 - f1: 0.9613\n","Epoch 569: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1115 - f1: 0.9613 - val_loss: 0.1518 - val_f1: 0.9638 - lr: 6.3627e-06\n","Epoch 570/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1121 - f1: 0.9645\n","Epoch 570: val_f1 did not improve from 0.98579\n","\n","Epoch 570: ReduceLROnPlateau reducing learning rate to 5.726417612095247e-06.\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1121 - f1: 0.9645 - val_loss: 0.1517 - val_f1: 0.9637 - lr: 6.3627e-06\n","Epoch 571/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1110 - f1: 0.9634\n","Epoch 571: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 243ms/step - loss: 0.1110 - f1: 0.9634 - val_loss: 0.1529 - val_f1: 0.9637 - lr: 5.7264e-06\n","Epoch 572/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1202 - f1: 0.9519\n","Epoch 572: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1202 - f1: 0.9519 - val_loss: 0.1509 - val_f1: 0.9640 - lr: 5.7264e-06\n","Epoch 573/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1128 - f1: 0.9620\n","Epoch 573: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1128 - f1: 0.9620 - val_loss: 0.1524 - val_f1: 0.9638 - lr: 5.7264e-06\n","Epoch 574/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1173 - f1: 0.9264\n","Epoch 574: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1173 - f1: 0.9264 - val_loss: 0.1525 - val_f1: 0.9638 - lr: 5.7264e-06\n","Epoch 575/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1136 - f1: 0.9589\n","Epoch 575: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1136 - f1: 0.9589 - val_loss: 0.1627 - val_f1: 0.9638 - lr: 5.7264e-06\n","Epoch 576/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1125 - f1: 0.9645\n","Epoch 576: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1125 - f1: 0.9645 - val_loss: 0.1631 - val_f1: 0.9637 - lr: 5.7264e-06\n","Epoch 577/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1144 - f1: 0.9648\n","Epoch 577: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1144 - f1: 0.9648 - val_loss: 0.1595 - val_f1: 0.9637 - lr: 5.7264e-06\n","Epoch 578/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1145 - f1: 0.9665\n","Epoch 578: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1145 - f1: 0.9665 - val_loss: 0.1559 - val_f1: 0.9638 - lr: 5.7264e-06\n","Epoch 579/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1090 - f1: 0.9630\n","Epoch 579: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1090 - f1: 0.9630 - val_loss: 0.1539 - val_f1: 0.9638 - lr: 5.7264e-06\n","Epoch 580/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1119 - f1: 0.9658\n","Epoch 580: val_f1 did not improve from 0.98579\n","\n","Epoch 580: ReduceLROnPlateau reducing learning rate to 5.15377605552203e-06.\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1119 - f1: 0.9658 - val_loss: 0.1552 - val_f1: 0.9638 - lr: 5.7264e-06\n","Epoch 581/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1142 - f1: 0.9640\n","Epoch 581: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1142 - f1: 0.9640 - val_loss: 0.1573 - val_f1: 0.9638 - lr: 5.1538e-06\n","Epoch 582/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1134 - f1: 0.9617\n","Epoch 582: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1134 - f1: 0.9617 - val_loss: 0.1576 - val_f1: 0.9638 - lr: 5.1538e-06\n","Epoch 583/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1131 - f1: 0.9640\n","Epoch 583: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1131 - f1: 0.9640 - val_loss: 0.1571 - val_f1: 0.9637 - lr: 5.1538e-06\n","Epoch 584/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1103 - f1: 0.9689\n","Epoch 584: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 239ms/step - loss: 0.1103 - f1: 0.9689 - val_loss: 0.1560 - val_f1: 0.9637 - lr: 5.1538e-06\n","Epoch 585/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1136 - f1: 0.9665\n","Epoch 585: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1136 - f1: 0.9665 - val_loss: 0.1567 - val_f1: 0.9637 - lr: 5.1538e-06\n","Epoch 586/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1138 - f1: 0.9650\n","Epoch 586: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 241ms/step - loss: 0.1138 - f1: 0.9650 - val_loss: 0.1567 - val_f1: 0.9637 - lr: 5.1538e-06\n","Epoch 587/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1120 - f1: 0.9619\n","Epoch 587: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 240ms/step - loss: 0.1120 - f1: 0.9619 - val_loss: 0.1561 - val_f1: 0.9637 - lr: 5.1538e-06\n","Epoch 588/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1171 - f1: 0.9581\n","Epoch 588: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 238ms/step - loss: 0.1171 - f1: 0.9581 - val_loss: 0.1628 - val_f1: 0.9637 - lr: 5.1538e-06\n","Epoch 589/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1121 - f1: 0.9641\n","Epoch 589: val_f1 did not improve from 0.98579\n","10/10 [==============================] - 2s 237ms/step - loss: 0.1121 - f1: 0.9641 - val_loss: 0.1617 - val_f1: 0.9635 - lr: 5.1538e-06\n","Epoch 590/1500\n","10/10 [==============================] - ETA: 0s - loss: 0.1179 - f1: 0.9317\n","Epoch 590: val_f1 did not improve from 0.98579\n","\n","Epoch 590: ReduceLROnPlateau reducing learning rate to 4.638398286260781e-06.\n","10/10 [==============================] - 2s 242ms/step - loss: 0.1179 - f1: 0.9317 - val_loss: 0.1591 - val_f1: 0.9637 - lr: 5.1538e-06\n"]}],"source":["# Обучение модели\n","history = model.fit(\n","    X_train_nn,\n","    y_train_nn, \n","    validation_split = 0.10, # доля обучающей выборки, которая идёт на валидацию\n","    epochs=1500,\n","    verbose=1,\n","    callbacks = callbacks_list\n",")"]},{"cell_type":"markdown","id":"dqaQMzAySEQJ","metadata":{"id":"dqaQMzAySEQJ"},"source":["### Predict"]},{"cell_type":"code","execution_count":70,"id":"r-dM4kDcSEQL","metadata":{"id":"r-dM4kDcSEQL"},"outputs":[],"source":["# Загружаем веса с лучшим результатом и сохраняем на диске\n","model.load_weights(PATH_BEST_MODEL+'best_model.hdf5')\n","model.save_weights(PATH_BEST_MODEL+'best_weights.hdf5')\n","model.save(PATH_BEST_MODEL+'best_model_saved.hdf5')"]},{"cell_type":"code","execution_count":71,"id":"O_Y1agAuSEQL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_Y1agAuSEQL","outputId":"8770d289-6ccc-4e71-9fa7-c5000520729d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 60ms/step\n","(54, 100)\n"]},{"data":{"text/plain":["array([[4, 4, 4, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 7, 7, 7],\n","       [7, 7, 7, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 4, 4, 4]], dtype=int64)"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["# model.load_weights(PATH_BEST_MODEL+'best_model.hdf5')\n","y_pred_nn = model.predict(X_test_nn).argmax(axis=-1)\n","\n","print(y_pred_nn.shape)\n","y_pred_nn"]},{"cell_type":"code","execution_count":72,"id":"lmRxDjsASEQM","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lmRxDjsASEQM","outputId":"7704623b-d199-4a99-b6da-c7d0ac88b05a"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5400,)\n"]},{"data":{"text/plain":["array([4, 4, 4, ..., 4, 4, 4], dtype=int64)"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = np.concatenate([arr for arr in y_pred_nn])\n","\n","print(y_pred.shape)\n","y_pred"]},{"cell_type":"code","execution_count":74,"id":"5Up-etUfSEQO","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"5Up-etUfSEQO","outputId":"88741407-3374-45d7-99ed-4fbb15f7394b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sample-timestep</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>323-0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>323-1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>323-2</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>323-3</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5396</th>\n","      <td>376-96</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5397</th>\n","      <td>376-97</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5398</th>\n","      <td>376-98</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5399</th>\n","      <td>376-99</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5400 rows × 2 columns</p>\n","</div>"],"text/plain":["     sample-timestep  class\n","0              323-0      4\n","1              323-1      4\n","2              323-2      4\n","3              323-3      4\n","...              ...    ...\n","5396          376-96      4\n","5397          376-97      4\n","5398          376-98      4\n","5399          376-99      4\n","\n","[5400 rows x 2 columns]"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["# Сохраняем результат предсказания модели в отдельный файл\n","y_test = pd.read_csv(os.path.join(PATH, './sample_submission.csv'))\n","y_test['class'] = y_pred\n","y_test.to_csv(PATH_BEST_MODEL+'y_test_4lstm.csv', index=False)\n","y_test"]},{"cell_type":"code","execution_count":75,"id":"4r46cAR7SEQO","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4r46cAR7SEQO","outputId":"59d889c4-1728-482d-9a82-74501ed40b77"},"outputs":[{"data":{"text/plain":["0    3330\n","5     339\n","6     299\n","4     267\n","3     267\n","8     263\n","2     220\n","7     213\n","1     202\n","Name: class, dtype: int64"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["y_test['class'].value_counts()"]}],"metadata":{"colab":{"collapsed_sections":["V0lyIpL2J9yc","729317ea-f0ef-478e-a854-0901a35dc330","385327d2-f8ae-48c9-b435-d7da8b4451f9","28ab5c4f-9f39-444a-a172-fa70a572d318","3eb9cbaf-7c94-4a41-a8db-7f4d5b4d75c4"],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"vscode":{"interpreter":{"hash":"b7ce4856bb191254866f13834f1feb508e008bc3e4294ce194585e573eb913ce"}}},"nbformat":4,"nbformat_minor":5}
